{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are loaded by default in Raku ***chatbooks*** (of \"Jupyter::Chatbook\") but we show them here if \"Jupyter::Kernel\" is used:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "use LLM::Functions;\n",
    "use LLM::Prompts;\n",
    "use Text::SubParsers;\n",
    "use Data::TypeSystem;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "## Direct LLM access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "As of the latest available data, the population of Brazil is estimated to be around 212 million people."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#%chat t0\n",
    "How many people live in Brazil?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Към последните налични данни, населението на Бразилия се оценява на около 212 милиона души."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#%chat t0\n",
    "Translated|Bulgarian^"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Well, darlin', I am Miss Anne, delighted to make your acquaintance. How may I be of service to you on this fine day?"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#%chat sb, prompt=@SouthernBelleSpeak\n",
    "Hi! Who are you?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Mmm, greetings! Yoda, I am. Speak in riddles, I do. What seek you, hmm?"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#%chat yd, prompt=@Yoda\n",
    "Hi! Who are you?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Mmm, a lightsaber, I have. Green, its color is. Many students I had, hmm. Train in the ways of the Force, they did. Countless, the number is. Seek wisdom, they did. Strong, the Force is in them. Hmm."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#%chat yd \n",
    "What is the color of your laser saber? How many students did you have?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "## LLM pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  \"Andaman and Nicobar Islands\": 380581,\n",
       "  \"Andhra Pradesh\": 49577103,\n",
       "  \"Arunachal Pradesh\": 1383727,\n",
       "  \"Assam\": 31205576,\n",
       "  \"Bihar\": 104099452,\n",
       "  \"Chandigarh\": 1055450,\n",
       "  \"Chhattisgarh\": 25545198,\n",
       "  \"Dadra and Nagar Haveli and Daman and Diu\": 585764,\n",
       "  \"Delhi\": 16787941,\n",
       "  \"Goa\": 1458545,\n",
       "  \"Gujarat\": 60439692,\n",
       "  \"Haryana\": 25351462,\n",
       "  \"Himachal Pradesh\": 6864602,\n",
       "  \"Jammu and Kashmir\": 12541302,\n",
       "  \"Jharkhand\": 32988134,\n",
       "  \"Karnataka\": 61095297,\n",
       "  \"Kerala\": 33406061,\n",
       "  \"Ladakh\": 290492,\n",
       "  \"Lakshadweep\": 73183,\n",
       "  \"Madhya Pradesh\": 72626809,\n",
       "  \"Maharashtra\": 112374333,\n",
       "  \"Manipur\": 2570390,\n",
       "  \"Meghalaya\": 2966889,\n",
       "  \"Mizoram\": 1097206,\n",
       "  \"Nagaland\": 1978502,\n",
       "  \"Odisha\": 41974218,\n",
       "  \"Puducherry\": 1247953,\n",
       "  \"Punjab\": 27743338,\n",
       "  \"Rajasthan\": 68548437,\n",
       "  \"Sikkim\": 610577,\n",
       "  \"Tamil Nadu\": 72147030,\n",
       "  \"Telangana\": 35003674,\n",
       "  \"Tripura\": 3673917,\n",
       "  \"Uttar Pradesh\": 199812341,\n",
       "  \"Uttarakhand\": 10086292,\n",
       "  \"West Bengal\": 91276115\n",
       "}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my $res = llm-synthesize([\n",
    "  \"What are the populations in India's states?\",\n",
    "  llm-prompt(\"NothingElse\")(\"JSON\")],\n",
    " llm-evaluator => llm-configuration(\"chatgpt\", model => \"gpt-3.5-turbo\", max-tokens => 1024)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{Andaman and Nicobar Islands => 380581, Andhra Pradesh => 49577103, Arunachal Pradesh => 1383727, Assam => 31205576, Bihar => 104099452, Chandigarh => 1055450, Chhattisgarh => 25545198, Dadra and Nagar Haveli and Daman and Diu => 585764, Delhi => 16787941, Goa => 1458545, Gujarat => 60439692, Haryana => 25351462, Himachal Pradesh => 6864602, Jammu and Kashmir => 12541302, Jharkhand => 32988134, Karnataka => 61095297, Kerala => 33406061, Ladakh => 290492, Lakshadweep => 73183, Madhya Pradesh => 72626809, Maharashtra => 112374333, Manipur => 2570390, Meghalaya => 2966889, Mizoram => 1097206, Nagaland => 1978502, Odisha => 41974218, Puducherry => 1247953, Punjab => 27743338, Rajasthan => 68548437, Sikkim => 610577, Tamil Nadu => 72147030, Telangana => 35003674, Tripura => 3673917, Uttar Pradesh => 199812341, Uttarakhand => 10086292, West Bengal => 91276115}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub-parser(\"JSON\", :drop).parse($res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ONLY give output in the form of a paragraph.\n",
      "Never explain, suggest, or converse. Only return output in the specified form.\n",
      "If code is requested, give only code, no explanations or accompanying text.\n",
      "If a table is requested, give only a table, no other explanations or accompanying text.\n",
      "Do not describe your output. \n",
      "Do not explain your output. \n",
      "Do not suggest anything. \n",
      "Do not respond with anything other than the singularly demanded output. \n",
      "Do not apologize if you are incorrect, simply try again, never apologize or add text.\n",
      "Do not add anything to the output, give only the output as requested. Your outputs can take any form as long as requested."
     ]
    }
   ],
   "source": [
    "print(llm-prompt(\"NothingElse\")())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "## Statistics of output data types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Workflow:** We want to see and evaluate the distribution of data types of LLM-function results:\n",
    "\n",
    "1. Make a pipeline of LLM-functions\n",
    "\n",
    "1. Create a list of random inputs \"expected\" by the pipeline\n",
    "\n",
    "    - Or use the same input multiple times.\n",
    "\n",
    "1. Deduce the data type of each output\n",
    "\n",
    "1. Compute descriptive statistics\n",
    "\n",
    "**Remark:** These kind of statistical workflows can be slow and expensive. (With the current line-up of LLM services.)\n",
    "\n",
    "Let us reuse the workflow from the previous section and enhance it with data type outputs finding. More precisely we:\n",
    "\n",
    "1. Generate random music artist names (using an LLM query)\n",
    "\n",
    "1. Retrieve short biography and discography for each music artist\n",
    "\n",
    "1. Extract album-and-release-date data for each artist (with NER-by-LLM)\n",
    "\n",
    "1. Deduce the type for each output, using several different type representations\n",
    "\n",
    "The data types are investigated with the functions deduce_type and record_types of [\"DataTypeSystem\"](https://pypi.org/project/DataTypeSystem/) , [AAp5]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we define a data retrieval function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-> **@args, *%args { #`(Block|5001862068200) ... }"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my &fdb = llm-function({\"What is the short biography and discography of the artist $_?\"}, e => llm-configuration(\"chatgpt\", max-tokens => 500))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we define (again) the NER function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-> **@args, *%args { #`(Block|5001768819304) ... }"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my &fner = llm-function({\"Extract $^a from the text: $^b . Give the result in a JSON format.\"}, e => 'chatgpt', form => sub-parser('JSON'):drop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we find 10 random music artists:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{music_artists => [Billie Eilish Kendrick Lamar Ariana Grande The Weeknd Taylor Swift Drake Beyoncé Ed Sheeran Rihanna Post Malone]}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my $artistNames = llm-function('', e=> 'chatgpt')(\"Give 10 random music artist names in a list in JSON format.\", \n",
    "                                        form => sub-parser('JSON'):drop);\n",
    "                                        \n",
    "$artistNames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Billie Eilish Kendrick Lamar Ariana Grande The Weeknd Taylor Swift Drake Beyoncé Ed Sheeran Rihanna Post Malone]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "$artistNames.head.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Billie Eilish Kendrick Lamar Ariana Grande The Weeknd Taylor Swift Drake Beyoncé Ed Sheeran Rihanna Post Malone]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my @artistNames2 = |$artistNames.head.value;\n",
    "@artistNames2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a loop that generates the biographies and does NER over them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "my @dbRes;\n",
       "for @artistNames2 -> $a {\n",
       "    my $text = fdb($a);\n",
       "    my $recs = fner('album names and release dates', $text);\n",
       "    @dbRes.push: $recs;\n",
       "}\n",
       "\n",
       "@dbRes;"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#% chat cw, prompt=@CodeWriterX|Raku\n",
    "Translate from Python:\n",
    "\n",
    "dbRes = []\n",
    "for a in artistNames2:\n",
    "    text = fdb(a)\n",
    "    recs = fner('album names and release dates', text)    \n",
    "    dbRes = dbRes + [recs, ]\n",
    "\n",
    "dbRes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{albums => [{name => When We All Fall Asleep, Where Do We Go?, release_date => 2019}]} {albums => [{name => Section.80, release_date => 2011} {name => good kid, m.A.A.d city, release_date => 2012} {name => To Pimp a Butterfly, release_date => 2015} {name => DAMN., release_date => 2017}]} {albums => [{name => Yours Truly, release_date => 2013} {name => My Everything, release_date => 2014} {name => Dangerous Woman, release_date => 2016} {name => Sweetener, release_date => 2018} {name => Thank U, Next, release_date => 2019} {name => Positions, release_date => 2020} {name => Dangerous Woman Diaries [Soundtrack], release_date => 2021} {name => K Bye for Now (SWT Live), release_date => 2019}]} {albums => [{name => Kiss Land, release_date => 2013} {name => Beauty Behind the Madness, release_date => 2015} {name => Starboy, release_date => 2016} {name => My Dear Melancholy, release_date => 2018} {name => After Hours, release_date => 2020}]} {albums => [{name => Fearless, release_date => 2008} {name => Speak Now, release_date => 2010} {name => Red, release_date => 2012} {name => 1989, release_date => 2014} {name => Reputation, release_date => 2017} {name => Lover, release_date => 2019}]} {albums => [{name => Thank Me Later, release_date => 2010} {name => Take Care, release_date => 2011} {name => Nothing Was the Same, release_date => 2013} {name => Views, release_date => 2016} {name => Scorpion, release_date => 2018}]} {albums => [{name => Dangerously in Love, release_date => 2003} {name => B'Day, release_date => 2006} {name => I Am... Sasha Fierce, release_date => 2008} {name => 4, release_date => 2011} {name => Beyoncé, release_date => 2013} {name => Lemonade, release_date => 2016} {name => Everything Is Love (with Jay-Z as The Carters), release_date => 2018} {name => Black Is King, release_date => 2020}]} {albums => [{name => +, release_date => 2011} {name => x, release_date => 2014} {name => ÷, release_date => 2017} {name => No.6 Collaborations Project, release_date => 2019}]} {albums => [{name => Music of the Sun, release_date => 2005} {name => A Girl Like Me, release_date => 2006} {name => Good Girl Gone Bad, release_date => 2007} {name => Rated R, release_date => 2009} {name => Loud, release_date => 2010} {name => Talk That Talk, release_date => 2011} {name => Unapologetic, release_date => 2012} {name => Anti, release_date => 2016}]} {albums => [{name => Stoney, release_date => 2016} {name => Beerbongs & Bentleys, release_date => 2018} {name => Hollywood's Bleeding, release_date => 2019}]}]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my @dbRes;\n",
    "for @artistNames2 -> $a {\n",
    "    my $text = fdb($a);\n",
    "    my $recs = fner('album names and release dates', $text);\n",
    "    @dbRes.push: $recs;\n",
    "}\n",
    "\n",
    "@dbRes;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\"><thead><tr><th>albums</th></tr></thead><tbody><tr><td><table border=\"1\"><thead><tr><th>release_date</th><th>name</th></tr></thead><tbody><tr><td>2019</td><td>When We All Fall Asleep, Where Do We Go?</td></tr></tbody></table></td></tr><tr><td><table border=\"1\"><thead><tr><th>release_date</th><th>name</th></tr></thead><tbody><tr><td>2011</td><td>Section.80</td></tr><tr><td>2012</td><td>good kid, m.A.A.d city</td></tr><tr><td>2015</td><td>To Pimp a Butterfly</td></tr><tr><td>2017</td><td>DAMN.</td></tr></tbody></table></td></tr><tr><td><table border=\"1\"><thead><tr><th>name</th><th>release_date</th></tr></thead><tbody><tr><td>Yours Truly</td><td>2013</td></tr><tr><td>My Everything</td><td>2014</td></tr><tr><td>Dangerous Woman</td><td>2016</td></tr><tr><td>Sweetener</td><td>2018</td></tr><tr><td>Thank U, Next</td><td>2019</td></tr><tr><td>Positions</td><td>2020</td></tr><tr><td>Dangerous Woman Diaries [Soundtrack]</td><td>2021</td></tr><tr><td>K Bye for Now (SWT Live)</td><td>2019</td></tr></tbody></table></td></tr></tbody></table>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#% html\n",
    "@dbRes.head(3) ==> to-html()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we call deduce_type on each LLM output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assoc(Atom((Str)), Vector(Assoc(Atom((Str)), Atom((Str)), 2), 1), 1)\n",
      "Assoc(Atom((Str)), Vector(Assoc(Atom((Str)), Atom((Str)), 2), 4), 1)\n",
      "Assoc(Atom((Str)), Vector(Assoc(Atom((Str)), Atom((Str)), 2), 8), 1)\n",
      "Assoc(Atom((Str)), Vector(Assoc(Atom((Str)), Atom((Str)), 2), 5), 1)\n",
      "Assoc(Atom((Str)), Vector(Assoc(Atom((Str)), Atom((Str)), 2), 6), 1)\n",
      "Assoc(Atom((Str)), Vector(Assoc(Atom((Str)), Atom((Str)), 2), 5), 1)\n",
      "Assoc(Atom((Str)), Vector(Assoc(Atom((Str)), Atom((Str)), 2), 8), 1)\n",
      "Assoc(Atom((Str)), Vector(Assoc(Atom((Str)), Atom((Str)), 2), 4), 1)\n",
      "Assoc(Atom((Str)), Vector(Assoc(Atom((Str)), Atom((Str)), 2), 8), 1)\n",
      "Assoc(Atom((Str)), Vector(Assoc(Atom((Str)), Atom((Str)), 2), 3), 1)\n"
     ]
    }
   ],
   "source": [
    ".say for @dbRes.map({ deduce-type($_) })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we redo the type deduction using the argument setting tally=True :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assoc(Atom((Str)), Vector(Assoc(Atom((Str)), Atom((Str)), 2), 1), 1)\n",
      "Assoc(Atom((Str)), Vector(Assoc(Atom((Str)), Atom((Str)), 2), 4), 1)\n",
      "Assoc(Atom((Str)), Vector(Assoc(Atom((Str)), Atom((Str)), 2), 8), 1)\n",
      "Assoc(Atom((Str)), Vector(Assoc(Atom((Str)), Atom((Str)), 2), 5), 1)\n",
      "Assoc(Atom((Str)), Vector(Assoc(Atom((Str)), Atom((Str)), 2), 6), 1)\n",
      "Assoc(Atom((Str)), Vector(Assoc(Atom((Str)), Atom((Str)), 2), 5), 1)\n",
      "Assoc(Atom((Str)), Vector(Assoc(Atom((Str)), Atom((Str)), 2), 8), 1)\n",
      "Assoc(Atom((Str)), Vector(Assoc(Atom((Str)), Atom((Str)), 2), 4), 1)\n",
      "Assoc(Atom((Str)), Vector(Assoc(Atom((Str)), Atom((Str)), 2), 8), 1)\n",
      "Assoc(Atom((Str)), Vector(Assoc(Atom((Str)), Atom((Str)), 2), 3), 1)\n"
     ]
    }
   ],
   "source": [
    ".say for @dbRes.map({ deduce-type($_):tally })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another record types finding call over the dictionaries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({name => (Str), release_date => (Str)})\n",
      "({name => (Str), release_date => (Str)} {name => (Str), release_date => (Str)} {name => (Str), release_date => (Str)} {name => (Str), release_date => (Str)})\n",
      "({name => (Str), release_date => (Str)} {name => (Str), release_date => (Str)} {name => (Str), release_date => (Str)} {name => (Str), release_date => (Str)} {name => (Str), release_date => (Str)} {name => (Str), release_date => (Str)} {name => (Str), release_date => (Str)} {name => (Str), release_date => (Str)})\n",
      "({name => (Str), release_date => (Str)} {name => (Str), release_date => (Str)} {name => (Str), release_date => (Str)} {name => (Str), release_date => (Str)} {name => (Str), release_date => (Str)})\n",
      "({name => (Str), release_date => (Str)} {name => (Str), release_date => (Str)} {name => (Str), release_date => (Str)} {name => (Str), release_date => (Str)} {name => (Str), release_date => (Str)} {name => (Str), release_date => (Str)})\n",
      "({name => (Str), release_date => (Str)} {name => (Str), release_date => (Str)} {name => (Str), release_date => (Str)} {name => (Str), release_date => (Str)} {name => (Str), release_date => (Str)})\n",
      "({name => (Str), release_date => (Str)} {name => (Str), release_date => (Str)} {name => (Str), release_date => (Str)} {name => (Str), release_date => (Str)} {name => (Str), release_date => (Str)} {name => (Str), release_date => (Str)} {name => (Str), release_date => (Str)} {name => (Str), release_date => (Str)})\n",
      "({name => (Str), release_date => (Str)} {name => (Str), release_date => (Str)} {name => (Str), release_date => (Str)} {name => (Str), release_date => (Str)})\n",
      "({name => (Str), release_date => (Str)} {name => (Str), release_date => (Str)} {name => (Str), release_date => (Str)} {name => (Str), release_date => (Str)} {name => (Str), release_date => (Str)} {name => (Str), release_date => (Str)} {name => (Str), release_date => (Str)} {name => (Str), release_date => (Str)})\n",
      "({name => (Str), release_date => (Str)} {name => (Str), release_date => (Str)} {name => (Str), release_date => (Str)})\n"
     ]
    }
   ],
   "source": [
    ".say for @dbRes.map({ record-types($_.values.head) })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The statistics show that most likely the output we get from the execution of the LLM-functions pipeline is a list of a string and a dictionary. The dictionaries are most likely to be of length one, with \"albums\" as the key."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RakuChatbook",
   "language": "raku",
   "name": "raku"
  },
  "language_info": {
   "file_extension": ".raku",
   "mimetype": "text/x-raku",
   "name": "raku",
   "version": "6.d"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
