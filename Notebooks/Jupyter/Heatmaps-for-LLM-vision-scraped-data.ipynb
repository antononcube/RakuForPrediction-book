{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Heatmaps for LLM vision scraped data\n",
    "\n",
    "Anton Antonov   \n",
    "[RakuForPrediction at WordPress](https://rakuforprediction.wordpress.com)   \n",
    "[RakuForPrediction-book at GitHub](https://github.com/antononcube/RakuForPrediction-book)    \n",
    "December 2023   \n",
    "January 2024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "\n",
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this document we show the use Artificial Intelligence (AI) Vision and Large Language Models (LLMs) for data scraping from images and Web pages and and we present heatmap plots corresponding to the scraped data. \n",
    "\n",
    "The LLM utilization and visualization are done in chat-enabled Jupyter notebook with a Raku kernel; \"chatbook\" for short. \n",
    "See [\"Jupyter::Chatbook\"](https://raku.land/zef:antononcube/Jupyter::Chatbook), [AAp4, AAv3].\n",
    "\n",
    "The heatmap plots in the Jupyter notebook are done with the package [\"JavaScript::D3\"](https://raku.land/zef:antononcube/JavaScript::D3), [AAp8, AAv1, AAv2]. (Heatmap plots were recently implemented.)\n",
    "\n",
    "We use data from sites dedicated of tracking Russian and Ukrainian casualties in NATO's war in Ukraine, (2022-present):\n",
    "\n",
    "- Russian casualties: [Mediazona](https://en.zona.media/article/2022/05/20/casualties_eng), [MZ1]\n",
    "- Ukrainian casualties: [UALosses](https://ualosses.org/), [UAL1]\n",
    "\n",
    "**Remark:** Note the UALosses is relatively new provides too few records of Ukrainian losses. The casualties of Medizona and UALosses should be considered underestimates, because of the methodologies they use. (Tracking and verifying online records.) See:\n",
    "- Section [\"Our methods\"](https://en.zona.media/article/2022/05/20/casualties_eng) of Mediazona\n",
    "- Page [\"About the project\"](https://ualosses.org/about/) of UALosses \n",
    "\n",
    "This document is a complement to the document [\"Extracting Russian casualties in Ukraine data from Mediazona publications\"](https://mathematicaforprediction.wordpress.com/2023/12/15/extracting-russian-casualties-in-ukraine-data-from-mediazona-publications), [AA4], \n",
    "and it uses AI Vision and LLM functionalities described in [AA1-AA3]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outline\n",
    "\n",
    "Here is an outline of the workflow steps shown below:\n",
    "\n",
    "1. Setup (packages and JavaScript plotting)\n",
    "2. Get a screenshot of Russian casualties heatmap plot from [Mediazona](https://en.zona.media/article/2022/05/20/casualties_eng), [MZ1]\n",
    "3. Using OpenAI's AI Vision extract data from the screenshot\n",
    "4. Verify and manually adjust the obtained data \n",
    "5. Make a heatmap plot\n",
    "6. Verify the plotted data\n",
    "7. Download page with regional Ukrainian casualties from [UALosses](https://ualosses.org/regions/), [UAL1]\n",
    "8. Use LLM to obtain the tabular data for those casualties \n",
    "9. Adjust, translate, or match names of regions (via LLMs)\n",
    "10. Make the corresponding heatmap plot\n",
    "11. Observations and conclusions   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we load the necessary packages and setup chatbook's environment for Javascript plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use JSON::Fast;\n",
    "use HTTP::Tiny;\n",
    "\n",
    "use Data::Generators;\n",
    "use Data::Reshapers;\n",
    "use Data::Summarizers;\n",
    "\n",
    "use JavaScript::D3;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%% javascript\n",
    "require.config({\n",
    "     paths: {\n",
    "     d3: 'https://d3js.org/d3.v7.min'\n",
    "}});\n",
    "\n",
    "require(['d3'], function(d3) {\n",
    "     console.log(d3);\n",
    "});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%js\n",
    "js-d3-list-line-plot((^40).roll(120), background => '#282828', color => 'orange')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "## Heatmap screenshot import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we get a screenshot image from [AAr1, MZ1] of the Russian casualties and we import it into the chatbook's session: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#% markdown\n",
    "my $url = 'https://raw.githubusercontent.com/antononcube/SystemModeling/master/Projects/War-modeling/Diagrams/Mediazona-Russian-casualties-choropleth-upto-2024-01-19.png';\n",
    "my $img = image-import($url);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remark:** The function `image-import` is from the package [\"Image::Markup::Utilities\"](https://raku.land/zef:antononcube/Image::Markup::Utilities), [AAp5], which is automatically loaded in a notebook session of [\"Jupyter::Chatbook\"](https://raku.land/zef:antononcube/Jupyter::Chatbook), [AAp4]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "\n",
    "## Data extraction via AI Vision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we extract the data from imported screenshot using the function `llm-vision-synthesize`, [AAp1, AAp2, AA3]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm-vision-synthesize(\"Give row-wise the Russian states and numbers in the squares of the choropleth.\", $url, max-tokens => 2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result we get has the data from the screenshot, but in order to make a heatmap plot we would benefit from a more structured data representation that reflects the Geo-inspired structure of the choropleth. \n",
    "\n",
    "Here is we prepare and use a more detailed and instructive prompt and combine it with:\n",
    "- JSON only prompt from [\"LLM::Prompts\"](https://raku.land/zef:antononcube/LLM::Prompts), [AAp3]\n",
    "- JSON sub-parser from [\"Text::SubParsers\"](https://raku.land/zef:antononcube/Text::SubParsers), [AAp6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my $p = q:to/END/;\n",
    "The image has boxes arranged in jagged array. \n",
    "The full array would have been with 11 rows and 17 columns. \n",
    "Give a JSON dictionary of the content of the boxes in the image. \n",
    "The keys should be matrix coordinates, the values are lists corresponding to the content of the boxes.\n",
    "END\n",
    "\n",
    "my $res = llm-vision-synthesize([$p, llm-prompt(\"NothingElse\")(\"JSON\")], $url, max-tokens => 2000, form => sub-parser('JSON'):drop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remark:** Again, the packages \"LLM::Prompts\", \"Text::SubParsers\" are automatically loaded in a chatbook session."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to explore the obtained data further we inform ourselves about its structure: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deduce-type($res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remark:** The function `deduce-type` is from the package [\"Data::TypeSystem\"](https://raku.land/zef:antononcube/Data::TypeSystem), [AAp7], which is automatically loaded in a chatbook session. \"Data::TypeSystem\" is used other data-transformation packages, and, in \"JavaScript::D3\", [AAp8], used for the heatmaps below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the deduced type result we see that the structure corresponds to what we specified in the prompt -- a list of pairs. \n",
    "But the JSON conversion from the sub-parser gives:\n",
    "- Keys that are not two-element lists of coodinates, but (corresponding) strings\n",
    "- Values that are lists of two strings (instead of a string and a number)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the data above is transformed into a dataset (a list of hash-maps):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my @ds3D = $res.map({ <y x z label>.Array Z=> [ |from-json($_.key), $_.value[1].Int, $_.value ].flat })>>.Hash;\n",
    "say dimensions(@ds3D);\n",
    "say deduce-type(@ds3D);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using that dataset we can overview the extracted data in the corresponding choropleth (or heatmap plot):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%js\n",
    "js-d3-heatmap-plot(@ds3D, width => 1200, plot-labels-font-size =>10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the vertical orientation is inverted. We got matrix coordinates, i.e. row indexes are ordered top-bottom. \n",
    "We are given heatmap plot bottom-top."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "## Manual data adjustment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we adjust extracted data in order to produce a heatmap that corresponds to that of Midiazona.\n",
    "We also, opportunistically, verify the data results. (Correct AI Vision recognition of text and numbers should be both trusted and verified.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the manual adjustment of the data (placed into a new data structure):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my %locCas = (\n",
    "   (1, 1) => [\"StPete\", 480], (1, 4) => [\"Murman\", 256], (1, 16) => [\"Chukot\", 44], (1, 17) => [\"Kmchtk\", 126],\n",
    "   (2, 1) => [\"Moscow\", 482], (2, 3) => [\"Karel\", 295], (2, 8) => [\"Nenets\", 44], (2, 9) => [\"Yamal\", 141], (2, 12) => [\"Krsyar\", 875], (2, 16) => [\"Mgadan\", 111],\n",
    "   \n",
    "   (3, 2) => [\"Len Obl\", 428], (3, 3) => [\"Novgrd\", 246], (3, 4) => [\"Vlgda\", 413], (3, 8) => [\"Arkngl\", 520], (3, 9) => [\"Komi\", 428], (3, 10) => [\"Hant-Ma\", 414], (3, 11) => [\"Tyumen\", 407], (3, 12) => [\"Tomsk\", 259], (3, 13) => [\"Kuzbas\", 904], (3, 14) => [\"Irkut\", 844],\n",
    "   (3, 15) => [\"Yakut\", 387], (3, 16) => [\"Khabar\", 196], (3, 17) => [\"Skhlin\", 392],\n",
    "   \n",
    "   (4, 1) => [\"Klngd\", 470], (4, 2) => [\"Pskov\", 328], (4, 3) => [\"Tver\", 446], (4, 4) => [\"Yarslv\", 262], (4, 5) => [\"Ivnovo\", 335], (4, 6) => [\"Kstrma\", 242], (4, 7) => [\"Mari-El\", 296], (4, 8) => [\"Kirov\", 476], (4, 9) => [\"Perm\", 1019], (4, 10) => [\"Yekat\", 1449], (4, 11) => [\"Kurgan\", 301], (4, 12) => [\"Novsib\", 790], (4, 13) => [\"Khakas\", 259],\n",
    "   (4, 14) => [\"Buryat\", 1117], (4, 15) => [\"Amursk\", 192],\n",
    "   \n",
    "   (5, 2) => [\"Smlnsk\", 186], (5, 3) => [\"Kaluga\", 233], (5, 4) => [\"Msc Obl\", 1125], (5, 5) => [\"Vldmr\", 358], (5, 6) => [\"Nzhny\", 733], (5, 7) => [\"Chuvas\", 347], (5, 8) => [\"Tatar\", 943], (5, 9) => [\"Udmurt\", 521], (5, 10) => [\"Chelya\", 1191], (5, 11) => [\"Omsk\", 623], (5, 12) => [\"Alt Kr\", 679],\n",
    "   (5, 13) => [\"Tyva\", 486], (5, 14) => [\"Zabayk\", 829], (5, 15) => [\"Ev AO\", 57], (5, 16) => [\"Primor\", 731],\n",
    "   \n",
    "   (6, 2) => [\"Brnsk\", 535], (6, 3) => [\"Orel\", 255], (6, 4) => [\"Tula\", 253], (6, 5) => [\"Ryazan\", 291], (6, 6) => [\"Mordov\", 192], (6, 7) => [\"Ulyan\", 451],\n",
    "   (6, 8) => [\"Samara\", 928], (6, 9) => [\"Bashkr\", 1353], (6, 12) => [\"Altai\", 172],\n",
    "   \n",
    "   (7, 3) => [\"Kursk\", 407], (7, 4) => [\"Liptsk\", 324], (7, 5) => [\"Tambov\", 284], (7, 6) => [\"Penza\", 291], (7, 7) => [\"Saratv\", 853], (7, 8) => [\"Orenbg\", 830],\n",
    "   \n",
    "   (8, 4) => [\"Belgrd\", 501], (8, 5) => [\"Vrnzeh\", 531], (8, 6) => [\"Volggr\", 1038],\n",
    "   \n",
    "   (9, 1) => [\"Crimea\", 407], (9, 3) => [\"Adygea\", 117], (9, 4) => [\"Kuban\", 1640], (9, 5) => [\"Rostov\", 1143], (9, 6) => [\"Kalmyk\", 121], (9, 7) => [\"Astrkn\", 358],\n",
    "   \n",
    "   (10, 1) => [\"Sevast\", 144], (10, 4) => [\"Kar-Chr\", 99], (10, 5) => [\"Stavro\", 904], (10, 6) => [\"Chechn\", 234], (10, 7) => [\"Dagstn\", 808],\n",
    "   \n",
    "   (11, 4) => [\"Kab-Bal\", 132], (11, 5) => [\"Alania\", 401], (11, 6) => [\"Ingush\", 57],\n",
    "   \n",
    "   (10, 16) => [\"Foreign\", 243], (10, 17) => [\"N/A\", 271]\n",
    ");\n",
    "\n",
    "say \"No of records    : {%locCas.elems}\";\n",
    "say \"Total casualties : {%locCas.values.map(*[1]).sum}\";\n",
    "say deduce-type(%locCas);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remark:** The total number of casualties from the data structure is the same as in the screenshot from Mediazona above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------\n",
    "\n",
    "## Heatmap plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we transform the data into a dataset and show the data type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my @ds3D = %locCas.map({ <y x z label>.Array Z=> [ |$_.key.split(/\\h/)>>.Int, $_.value[1], $_.value ].flat })>>.Hash;\n",
    "say @ds3D.elems;\n",
    "say deduce-type(@ds3D);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the corresponding summary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sink records-summary(select-columns(@ds3D, <x y z>))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we transform the dataset to have:\n",
    "- Two-row labels\n",
    "- Separation gap for \"odd\" regions (Moscow, Crimea, etc.)\n",
    "- Casualty values that are suitably rescaled for more informative visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my @ds3D2 = @ds3D>>.clone.map({ $_<z> = sqrt($_<z>); $_<x> = $_<x> > 1 ?? $_<x> + 1 !! $_<x> ; $_<y> = 12 - $_<y>; $_<label> = \"<tspan>{$_<label>.head}</tspan><tspan dx='-{$_<label>.head.chars/2}em', dy='1em'>{$_<label>.tail}</tspan>\"; $_ });\n",
    "@ds3D2.elems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the heatmap plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%js\n",
    "js-d3-heatmap-plot(@ds3D2, width => 1100, height => 800,\n",
    "    x-tick-labels => (1..18),\n",
    "    plot-labels-font-size => 13,\n",
    "    plot-labels-color => 'white', \n",
    "    color-palette => 'Reds', \n",
    "    background => \"#282828\", \n",
    "    tick-labels-font-size => 0,\n",
    "    low-value => 0,\n",
    "    high-value => sqrt(1800),\n",
    "    mesh => 0.01\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "## Additional verifications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use LLMs do to some additional verification of the data.\n",
    "For example, we asks about certain summary statistics over Russia that might increase our confidence in the extracted data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#% chat, temperature=0.2\n",
    "What are types of the administrative divisions of Russia? \n",
    "Answer concisely, only the types and the integer count of the corresponding entities per type."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "\n",
    "## Scrape Ukrainian losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we import the web page of regional Ukrainian losses from [\"UALosses\"](https://ualosses.org/districts/), [UAL1]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my $response = HTTP::Tiny.new.get( 'https://ualosses.org/regions/' );\n",
    "my $htmlRes = $response<content>.decode;\n",
    "say $htmlRes.chars;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we show the table of from the imported page (by HTML applying a regex over its HTML code):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%html\n",
    "my $htmlTable = do with $htmlRes ~~ / '<table>' (.*) '</table>' / { $/.Str }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The easiest way -- and, maybe, the most reliable way -- to transform that HTML table into a Raku data structure is to use an LLM with a specially crafted prompt.\n",
    "\n",
    "Here is such an LLM invocation:\n",
    "- Uses the HTML table obtained above\n",
    "- Says that only JSON and nothing else should be returned\n",
    "- Post-process the result with a JSON sub-parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my $uaRes = llm-synthesize([\n",
    "    \"Convert the HTML table into a Raku list of hashmaps. The values of 'Death Count' and 'Population (2022)' are integers.\", \n",
    "    $htmlTable, \n",
    "    llm-prompt('NothingElse')('JSON')\n",
    "    ], \n",
    "    e => llm-configuration('chatgpt', model => 'gpt-3.5-turbo-16k-0613', max-tokens => 2000), \n",
    "    form => sub-parser('JSON'):drop\n",
    ");\n",
    "\n",
    "say deduce-type($uaRes);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we display the obtained data structure as an HTML table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#% html\n",
    "#my $dsUALosses = $uaRes.clone.map({ my %h = $_.Hash , %('Death Count' => $_{'Death Count'}.Int // 0, 'Population (2022)' => $_{'Population (2022)'}.Int); %h });\n",
    "my @dsUALosses = |$uaRes;  \n",
    "@dsUALosses ==> data-translation(field-names=>('Name', 'Population (2022)', 'Death Count', 'Death Count per Capita', 'Average age at death'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `data-translation` is from the package [\"Data::Translators\"](https://raku.land/zef:antononcube/Data::Translators), which is automatically loaded in a chatbook session."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a verification sum:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsUALosses.map( *{\"Death Count\"} ).sum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we make a dictionary of region (\"oblast\") name to casualties:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my %uaOblastCas = @dsUALosses.map({ $_<Name> => $_{\"Death Count\"} })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my @dsUALosses2 = @dsUALosses.map({ my %h = $_.Hash , %( EnglishName => %uaToEN{$_<Name>} // $_<Name> ); %h });\n",
    "#@dsUALosses2 = @dsUALosses2.map({ my %h = |$_.Hash , |%uaGeoCoords{$_<EnglishName>} //  %uaGeoCoords{$_<EnglishName> ~ ' Oblast'}; %h });\n",
    "@dsUALosses2 = @dsUALosses2.map({ %uaGeoCoords{$_<EnglishName>} // %uaGeoCoords{$_<EnglishName>.subst(' Oblast') } });\n",
    "#@dsUALosses2 ==> to-pretty-table()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "## Heatmap Ukraine casualties"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we prepare choropleth stencil for the Ukrainian losses: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my %uaLoc = (\n",
    "    (1, 1) => \"Volyn\", (1, 2) => \"Rivne\", (1, 5) => \"Chernigov\", (1, 6) => \"Sumy\",\n",
    "   \n",
    "    (2, 3) => \"Zhitomir\", (2, 4) => \"Kyiv\", (2, 4) => \"Kyyivska\",\n",
    "\n",
    "    (3, 1) => \"Lviv\", (3, 2) => \"Ternopil\", (3, 3) => \"Khmelnytskyi\", (3, 5) => \"Cherkask\", (3, 6) => \"Poltava\", (3, 7) => \"Kharkiv\",\n",
    "    \n",
    "    (4, 1) => \"Ivano-Frankivsk\", (4, 3) => \"Vinnica\", (4, 8) => \"Luhansk\",\n",
    " \n",
    "    (5, 1) => \"Zakarpattia\", (5, 2) => \"Chernivtsi\", (5, 5) => \"Kirovohrad\", (5, 6) => \"Dnipropetrovsk\", (5, 7) => \"Donetsk\",\n",
    "  \n",
    "    (6, 5) => \"Mykolayivsk\", (6, 6) => \"Zaporizhzhia\",\n",
    "\n",
    "    (7, 4) => \"Odesa\", (7, 6) => \"Kherson\"\n",
    ");\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the stencil was prepared using a Geo-data source different from [ualosses.org](https://ualosses.org/), \n",
    "here we formulate and execute an LLM request to make a dictionary that matches the administrative division names \n",
    "from the casualties table and stencil:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my %uaOblastNames = llm-synthesize([\n",
    "    \"Match the values of the list:\\n {to-json(%uaLoc.values)} \\n with the list: \\n {to-json(@dsUALosses.map(*<Name>))} \\n into a JSON dictionary.\",\n",
    "    llm-prompt('NothingElse')('JSON')\n",
    "    ], \n",
    "    e => llm-configuration('chatgpt', model => 'gpt-3.5-turbo-16k-0613', max-tokens => 2000), \n",
    "    form => sub-parser('JSON'):drop\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we fill-in the stencil with the casualties numbers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my %uaLocCas = %uaLoc.map({ $_.key => [$_.value, %uaOblastCas{ %uaOblastNames{$_.value} } // 0] })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we convert the hash-map into a dataset (suitable for displaying with \"JavaScript::D3\"):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my @dsUA3D = %uaLocCas.map({ <y x z label>.Array Z=> [ |$_.key.split(/\\h/)>>.Int, $_.value[1], $_.value ].flat })>>.Hash;\n",
    "say @dsUA3D.elems;\n",
    "say deduce-type(@dsUA3D);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with the Russian casualties heatmap plot above, here we transform the Ukrainian losses dataset to have:\n",
    "- Two-row labels\n",
    "- Casualty values that are suitably rescaled for more informative visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my @dsUA3D2 = @dsUA3D>>.clone.map({ $_<z> = sqrt($_<z>); $_<y> = 12 - $_<y>; $_<label> = \"<tspan>{$_<label>.head}</tspan><tspan dx='-{$_<label>.head.chars/2}em', dy='1em'>{$_<label>.tail}</tspan>\"; $_ });\n",
    "@dsUA3D2.elems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we make the heatmap plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%js\n",
    "js-d3-heatmap-plot(@dsUA3D2, width => 1000, height => 600,\n",
    "    x-tick-labels => (1..8),\n",
    "    plot-labels-font-size => 12,\n",
    "    plot-labels-color => 'white', \n",
    "    color-palette => 'Reds', \n",
    "    background => \"#282828\", \n",
    "    tick-labels-font-size => 0,\n",
    "    low-value => 0,\n",
    "    high-value => sqrt(1800),\n",
    "    mesh => 0.01\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "\n",
    "## Observation and conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In section we give several groups of observation and conclusions that came out doing the presented data scraping and plots."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choropleths\n",
    "\n",
    "- Suitable Geo-data for the choropleth stencils have to be obtained and tweaked.\n",
    "- Russia \n",
    "    - The initial values for the choropleth coordinates were derived via AI Vision.\n",
    "    - Review and manual adjustment was (of course) required.\n",
    "    - Since the total number of administration districts is 85, having a set of initial values sped up the final stencil derivation.\n",
    "- Ukraine \n",
    "    - The choropleth stencil coordinates were derived from a Geo plot using Mathematica.\n",
    "    - Compared to UALosses, Mathematica uses slightly different names of the Ukrainian administrative divisions (or regions.)\n",
    "- The choropleth stencils could be automatically derived from the actual geometric centers of the administrative divisions, but it seemed easier and less error-prone to make those stencils manually.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data scraping\n",
    "\n",
    "- AI Vision can be effectively used to get data from images in Web pages or other types of documents. See [AA1-AA4] for more details.\n",
    "- LLMs can be used to convert data elements -- like tables -- of Web pages into programming data structures (that suitable in further computations.)\n",
    "  - The data conversions we did using LLMs are done \"through JSON\", because:\n",
    "    - JSON is a popular well represented data format in LLMs training data\n",
    "    - Raku has good JSON-to-Raku and Raku-to-JSON converters.\n",
    "- Small discrepancies or errors from data scraping procedures can be smoothed, detected, or eliminated using LLMs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heatmap plots\n",
    "\n",
    "- The heatmap plot function `js-d3-heatmap-plot` of \"JavaScript:D3\" allows:\n",
    "  - Use of sparse data\n",
    "  - Rectangles with labels\n",
    "  - Different color palettes for the values of the rectangles\n",
    "  - Tunable fonts and colors for axis labels and plot labels\n",
    "- In order to have two-row labels in the rectangles special HTML-spec has to be used.\n",
    "  - That is constraint coming up from the implementation of the underlying [Javascript library D3](https://d3js.org)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "\n",
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Articles\n",
    "\n",
    "[AA1] Anton Antonov\n",
    "[\"AI vision via Raku\"](https://rakuforprediction.wordpress.com/2023/11/25/ai-vision-via-raku/),\n",
    "(2023),\n",
    "[RakuForPrediction at WordPress](https://rakuforprediction.wordpress.com).\n",
    "\n",
    "[AA2] Anton Antonov,\n",
    "[\"AI vision via Wolfram Language\"](https://community.wolfram.com/groups/-/m/t/3072318),\n",
    "(2023),\n",
    "[Wolfram Community](https://community.wolfram.com).\n",
    "\n",
    "[AA3] Anton Antonov\n",
    "[\"Day 24 – Streamlining AI vision workflows\"](https://raku-advent.blog/2023/12/24/day-24-streamlining-ai-vision-workflows/),\n",
    "(2023),\n",
    "[RakuAdventCalendar at WordPress](https://raku-advent.blog).\n",
    "\n",
    "[AA4] Anton Antonov,\n",
    "[\"Extracting Russian casualties in Ukraine data from Mediazona publications\"](https://mathematicaforprediction.wordpress.com/2023/12/15/extracting-russian-casualties-in-ukraine-data-from-mediazona-publications/),\n",
    "(2023),\n",
    "[MathematicaForPrediction at WordPress](https://mathematicaforprediction.wordpress.com).\n",
    "\n",
    "[MZ1] Mediazona, \n",
    "[Russian casualties in Ukraine](https://en.zona.media/article/2022/05/20/casualties_eng), \n",
    "(2022-2024).\n",
    "\n",
    "[UAL1] UALosses, \n",
    "[Ukrainian losses](https://ualosses.org/), \n",
    "(2023-2024)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Packages, repositories\n",
    "\n",
    "[AAp1] Anton Antonov,\n",
    "[WWW::OpenAI](https://github.com/antononcube/Raku-WWW-OpenAI) Raku package,\n",
    "(2023),\n",
    "[GitHub/antononcube](https://github.com/antononcube).\n",
    "\n",
    "\n",
    "[AAp2] Anton Antonov,\n",
    "[LLM::Functions](https://github.com/antononcube/Raku-LLM-Functions) Raku package,\n",
    "(2023),\n",
    "[GitHub/antononcube](https://github.com/antononcube).\n",
    "\n",
    "\n",
    "[AAp3] Anton Antonov,\n",
    "[LLM::Prompts](https://github.com/antononcube/Raku-LLM-Prompts) Raku package,\n",
    "(2023),\n",
    "[GitHub/antononcube](https://github.com/antononcube).\n",
    "\n",
    "\n",
    "[AAp4] Anton Antonov,\n",
    "[Jupyter::Chatbook](https://github.com/antononcube/Raku-Jupyter-Chatbook) Raku package,\n",
    "(2023),\n",
    "[GitHub/antononcube](https://github.com/antononcube).\n",
    "\n",
    "\n",
    "[AAp5] Anton Antonov,\n",
    "[Image::Markup::Utilities](https://github.com/antononcube/Raku-Image-Markup-Utilities) Raku package,\n",
    "(2023),\n",
    "[GitHub/antononcube](https://github.com/antononcube).\n",
    "\n",
    "\n",
    "[AAp6] Anton Antonov,\n",
    "[Text::SubParsers](https://github.com/antononcube/Raku-Text-SubParsers) Raku package,\n",
    "(2023),\n",
    "[GitHub/antononcube](https://github.com/antononcube).\n",
    "\n",
    "[AAp7] Anton Antonov,\n",
    "[Data::TypeSystem](https://github.com/antononcube/Raku-Data-TypeSystem) Raku package,\n",
    "(2023),\n",
    "[GitHub/antononcube](https://github.com/antononcube).\n",
    "\n",
    "[AAp8] Anton Antonov,\n",
    "[JavaScript::D3](https://github.com/antononcube/Raku-JavaScript-D3) Raku package,\n",
    "(2022-2023),\n",
    "[GitHub/antononcube](https://github.com/antononcube).\n",
    "\n",
    "[AAp9] Anton Antonov,\n",
    "[Data::Translators](https://github.com/antononcube/Raku-Data-Translators) Raku package,\n",
    "(2023),\n",
    "[GitHub/antononcube](https://github.com/antononcube).\n",
    "\n",
    "[AAr1] Anton Antonov,\n",
    "[SystemModeling at GitHub](https://github.com/antononcube/SystemModeling),\n",
    "(2020-2024),\n",
    "[GitHub/antononcube](https://github.com/antononcube)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Videos\n",
    "\n",
    "[AAv1] Anton Antonov,\n",
    "[\"The Raku-ju hijack hack for D3.js\"](https://www.youtube.com/watch?v=YIhx3FBWayo),\n",
    "(2022),\n",
    "[YouTube/@AAA4Prediction](https://www.youtube.com/@AAA4prediction).\n",
    "\n",
    "[AAv2] Anton Antonov,\n",
    "[\"Random mandalas generation (with D3.js via Raku)\"](https://www.youtube.com/watch?v=THNnofZEAn4),\n",
    "(2022),\n",
    "[YouTube/@AAA4Prediction](https://www.youtube.com/@AAA4prediction).\n",
    "\n",
    "[AAv3] Anton Antonov,\n",
    "[\"Integrating Large Language Models with Raku\"](https://www.youtube.com/watch?v=-OxKqRrQvh0),\n",
    "(2023),\n",
    "[YouTube/@therakuconference6823](https://www.youtube.com/@therakuconference6823)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RakuChatbook",
   "language": "raku",
   "name": "raku"
  },
  "language_info": {
   "file_extension": ".raku",
   "mimetype": "text/plain",
   "name": "raku",
   "version": "6.d"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
