{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Robust LLM pipelines\n",
    "\n",
    "### ***Raku version 0.9***\n",
    "\n",
    "Anton Antonov   \n",
    "[South FL Data Science Study Group](https://www.meetup.com/data-science-study-group-south-florida/events/301740295/)   \n",
    "July 2024   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------\n",
    "\n",
    "## What is this about?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We focus on five ways to build robust LLM pipelines (from software architecture / engineering perspective.)   \n",
    "The first (DSL) one is the most important."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. DSL for configuration-execution-conversion\n",
    "   - Infrastructural, language-design level solution\n",
    "2. Detailed, well crafted prompts\n",
    "   - AKA \"Prompt engineering\"\n",
    "3. Few-shot training with examples\n",
    "4. Via a Question Answering System (QAS) and code templates\n",
    "5. Using grammars\n",
    "   - Pareto principle application\n",
    "   - Or for filtering of multiple outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "## Universality of the methodology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Programmed in three different languages (Python, Raku, WL)\n",
    "\n",
    "- The method(s) are applied regardless of the software support\n",
    "\n",
    "- This presentation is with Raku-kernel Jupyter ***chatbook*** in VS Code\n",
    "    - There is a corresponding Python chatbook package\n",
    "    - Mathematica has chatbooks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remark:** The DSL for configuration-execution-conversion is described in detail in Stephen Wolfram's article: \n",
    "\n",
    "- [\"The New World of LLM Functions: Integrating LLM Technology into the Wolfram Language\"](https://writings.stephenwolfram.com/2023/05/the-new-world-of-llm-functions-integrating-llm-technology-into-the-wolfram-language/), [SW1]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "## Motivation example(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a setup of an LLM persona that generates [Google Charts](https://developers.google.com/chart) code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#% chat gc prompt, conf=chatgpt, model=gpt-4o, max-tokens=4096, temperature=0.4\n",
    "@CodeWriterX|'Google Charts'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because of recent events consider the following LLM request and responses:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#% chat gc > html\n",
    "Show a regional map of Cuba and the Caribbean islands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#% chat gc > html\n",
    "Show a regional map of Cuba and the Caribbean islands.\n",
    "Mark Havana's marine port. Use the div-id 'port'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "## DSL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separation of:\n",
    "\n",
    "  - LLM access configuration\n",
    "  - Invocation\n",
    "  - Post-processing of results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that:\n",
    "\n",
    "- This is a fundamental, infrastructural design\n",
    "- It is always applied regardless of how well is facilitated programmatically\n",
    "- (And, yes, we claim it is facilitated very well with Python, Raku, WL implementations.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the following **LLM-function**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-> **@args, *%args { #`(Block|3365964960968) ... }"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my &gdp = llm-function(\n",
    "    {\"GDP of $^a in $^b. \\n\" ~ llm-prompt('NothingElse')('JSON')}, \n",
    "    e => $conf4o,\n",
    "    form => sub-parser('JSON'):drop\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[countries => [{GDP => 25400, country => United States} {GDP => 17700, country => China} {GDP => 5040, country => Japan} {GDP => 4200, country => Germany} {GDP => 3200, country => India} {GDP => 3100, country => United Kingdom} {GDP => 2900, country => France} {GDP => 2100, country => Italy} {GDP => 2000, country => Canada} {GDP => 1800, country => South Korea}]]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my $res = &gdp('top 10 countries', 2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "countries => [{GDP => 25400, country => United States} {GDP => 17700, country => China} {GDP => 5040, country => Japan} {GDP => 4200, country => Germany} {GDP => 3200, country => India} {GDP => 3100, country => United Kingdom} {GDP => 2900, country => France} {GDP => 2100, country => Italy} {GDP => 2000, country => Canada} {GDP => 1800, country => South Korea}]\n"
     ]
    }
   ],
   "source": [
    ".say for |$res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** What did we expect to get as a result?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the result has an *expected* shape we can do this plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#% html\n",
    "js-google-charts('BarChart', \n",
    "    $res.Hash, \n",
    "    :$format, \n",
    "    :$backgroundColor,\n",
    "    :$legendTextStyle,\n",
    "    :$hAxis,\n",
    "    :$vAxis,\n",
    "    div-id => 'gdp'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the configuration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ".say for |$conf4o.Hash"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** Do we expect the same *data shape* of the results when running the LLM request / function:\n",
    "- Multiple times\n",
    "- With different LLMs / configurations\n",
    "- With different parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------\n",
    "\n",
    "## Sequence diagrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a sequence diagram that follows the steps of a typical creation procedure of LLM configuration- and evaluator objects, and the corresponding LLM-function that utilizes them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<svg id=\"mermaid-svg\" width=\"100%\" xmlns=\"http://www.w3.org/2000/svg\" style=\"max-width: 1256px; background-color: rgb(255, 255, 255);\" viewBox=\"-50 -10 1256 587.6666666666667\" role=\"graphics-document document\" aria-roledescription=\"sequence\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><style xmlns=\"http://www.w3.org/1999/xhtml\">@import url(\"https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.2/css/all.min.css\");</style><g><rect x=\"1000\" y=\"501.6666666666667\" fill=\"#eaeaea\" stroke=\"#666\" width=\"156\" height=\"65\" name=\"AnonFunc\" rx=\"3\" ry=\"3\" class=\"actor actor-bottom\"/><text x=\"1078\" y=\"534.1666666666667\" dominant-baseline=\"central\" alignment-baseline=\"central\" class=\"actor\" style=\"text-anchor: middle; font-size: 16px; font-weight: 400;\"><tspan x=\"1078\" dy=\"0\">Anonymous function</tspan></text></g><g><rect x=\"800\" y=\"501.6666666666667\" fill=\"#eaeaea\" stroke=\"#666\" width=\"150\" height=\"65\" name=\"LLMEval\" rx=\"3\" ry=\"3\" class=\"actor actor-bottom\"/><text x=\"875\" y=\"534.1666666666667\" dominant-baseline=\"central\" alignment-baseline=\"central\" class=\"actor\" style=\"text-anchor: middle; font-size: 16px; font-weight: 400;\"><tspan x=\"875\" dy=\"0\">LLM evaluator</tspan></text></g><g><rect x=\"600\" y=\"501.6666666666667\" fill=\"#eaeaea\" stroke=\"#666\" width=\"150\" height=\"65\" name=\"LLMConf\" rx=\"3\" ry=\"3\" class=\"actor actor-bottom\"/><text x=\"675\" y=\"534.1666666666667\" dominant-baseline=\"central\" alignment-baseline=\"central\" class=\"actor\" style=\"text-anchor: middle; font-size: 16px; font-weight: 400;\"><tspan x=\"675\" dy=\"0\">LLM configuration</tspan></text></g><g><rect x=\"400\" y=\"501.6666666666667\" fill=\"#eaeaea\" stroke=\"#666\" width=\"150\" height=\"65\" name=\"llmconf\" rx=\"3\" ry=\"3\" class=\"actor actor-bottom\"/><text x=\"475\" y=\"534.1666666666667\" dominant-baseline=\"central\" alignment-baseline=\"central\" class=\"actor\" style=\"text-anchor: middle; font-size: 16px; font-weight: 400;\"><tspan x=\"475\" dy=\"0\">llm-configuration</tspan></text></g><g><rect x=\"200\" y=\"501.6666666666667\" fill=\"#eaeaea\" stroke=\"#666\" width=\"150\" height=\"65\" name=\"llmfunc\" rx=\"3\" ry=\"3\" class=\"actor actor-bottom\"/><text x=\"275\" y=\"534.1666666666667\" dominant-baseline=\"central\" alignment-baseline=\"central\" class=\"actor\" style=\"text-anchor: middle; font-size: 16px; font-weight: 400;\"><tspan x=\"275\" dy=\"0\">llm-function</tspan></text></g><g><rect x=\"0\" y=\"501.6666666666667\" fill=\"#eaeaea\" stroke=\"#666\" width=\"150\" height=\"65\" name=\"User\" rx=\"3\" ry=\"3\" class=\"actor actor-bottom\"/><text x=\"75\" y=\"534.1666666666667\" dominant-baseline=\"central\" alignment-baseline=\"central\" class=\"actor\" style=\"text-anchor: middle; font-size: 16px; font-weight: 400;\"><tspan x=\"75\" dy=\"0\">User</tspan></text></g><g><line id=\"actor5\" x1=\"1078\" y1=\"5\" x2=\"1078\" y2=\"501.6666666666667\" class=\"200\" stroke-width=\"0.5px\" stroke=\"#999\"/><g id=\"root-5\"><rect x=\"1000\" y=\"0\" fill=\"#eaeaea\" stroke=\"#666\" width=\"156\" height=\"65\" name=\"AnonFunc\" rx=\"3\" ry=\"3\" class=\"actor actor-top\"/><text x=\"1078\" y=\"32.5\" dominant-baseline=\"central\" alignment-baseline=\"central\" class=\"actor\" style=\"text-anchor: middle; font-size: 16px; font-weight: 400;\"><tspan x=\"1078\" dy=\"0\">Anonymous function</tspan></text></g></g><g><line id=\"actor4\" x1=\"875\" y1=\"5\" x2=\"875\" y2=\"501.6666666666667\" class=\"200\" stroke-width=\"0.5px\" stroke=\"#999\"/><g id=\"root-4\"><rect x=\"800\" y=\"0\" fill=\"#eaeaea\" stroke=\"#666\" width=\"150\" height=\"65\" name=\"LLMEval\" rx=\"3\" ry=\"3\" class=\"actor actor-top\"/><text x=\"875\" y=\"32.5\" dominant-baseline=\"central\" alignment-baseline=\"central\" class=\"actor\" style=\"text-anchor: middle; font-size: 16px; font-weight: 400;\"><tspan x=\"875\" dy=\"0\">LLM evaluator</tspan></text></g></g><g><line id=\"actor3\" x1=\"675\" y1=\"5\" x2=\"675\" y2=\"501.6666666666667\" class=\"200\" stroke-width=\"0.5px\" stroke=\"#999\"/><g id=\"root-3\"><rect x=\"600\" y=\"0\" fill=\"#eaeaea\" stroke=\"#666\" width=\"150\" height=\"65\" name=\"LLMConf\" rx=\"3\" ry=\"3\" class=\"actor actor-top\"/><text x=\"675\" y=\"32.5\" dominant-baseline=\"central\" alignment-baseline=\"central\" class=\"actor\" style=\"text-anchor: middle; font-size: 16px; font-weight: 400;\"><tspan x=\"675\" dy=\"0\">LLM configuration</tspan></text></g></g><g><line id=\"actor2\" x1=\"475\" y1=\"5\" x2=\"475\" y2=\"501.6666666666667\" class=\"200\" stroke-width=\"0.5px\" stroke=\"#999\"/><g id=\"root-2\"><rect x=\"400\" y=\"0\" fill=\"#eaeaea\" stroke=\"#666\" width=\"150\" height=\"65\" name=\"llmconf\" rx=\"3\" ry=\"3\" class=\"actor actor-top\"/><text x=\"475\" y=\"32.5\" dominant-baseline=\"central\" alignment-baseline=\"central\" class=\"actor\" style=\"text-anchor: middle; font-size: 16px; font-weight: 400;\"><tspan x=\"475\" dy=\"0\">llm-configuration</tspan></text></g></g><g><line id=\"actor1\" x1=\"275\" y1=\"5\" x2=\"275\" y2=\"501.6666666666667\" class=\"200\" stroke-width=\"0.5px\" stroke=\"#999\"/><g id=\"root-1\"><rect x=\"200\" y=\"0\" fill=\"#eaeaea\" stroke=\"#666\" width=\"150\" height=\"65\" name=\"llmfunc\" rx=\"3\" ry=\"3\" class=\"actor actor-top\"/><text x=\"275\" y=\"32.5\" dominant-baseline=\"central\" alignment-baseline=\"central\" class=\"actor\" style=\"text-anchor: middle; font-size: 16px; font-weight: 400;\"><tspan x=\"275\" dy=\"0\">llm-function</tspan></text></g></g><g><line id=\"actor0\" x1=\"75\" y1=\"5\" x2=\"75\" y2=\"501.6666666666667\" class=\"200\" stroke-width=\"0.5px\" stroke=\"#999\"/><g id=\"root-0\"><rect x=\"0\" y=\"0\" fill=\"#eaeaea\" stroke=\"#666\" width=\"150\" height=\"65\" name=\"User\" rx=\"3\" ry=\"3\" class=\"actor actor-top\"/><text x=\"75\" y=\"32.5\" dominant-baseline=\"central\" alignment-baseline=\"central\" class=\"actor\" style=\"text-anchor: middle; font-size: 16px; font-weight: 400;\"><tspan x=\"75\" dy=\"0\">User</tspan></text></g></g><style>#mermaid-svg{font-family:\"trebuchet ms\",verdana,arial,sans-serif;font-size:16px;fill:#333;}#mermaid-svg .error-icon{fill:#552222;}#mermaid-svg .error-text{fill:#552222;stroke:#552222;}#mermaid-svg .edge-thickness-normal{stroke-width:2px;}#mermaid-svg .edge-thickness-thick{stroke-width:3.5px;}#mermaid-svg .edge-pattern-solid{stroke-dasharray:0;}#mermaid-svg .edge-pattern-dashed{stroke-dasharray:3;}#mermaid-svg .edge-pattern-dotted{stroke-dasharray:2;}#mermaid-svg .marker{fill:#333333;stroke:#333333;}#mermaid-svg .marker.cross{stroke:#333333;}#mermaid-svg svg{font-family:\"trebuchet ms\",verdana,arial,sans-serif;font-size:16px;}#mermaid-svg .actor{stroke:hsl(259.6261682243, 59.7765363128%, 87.9019607843%);fill:#ECECFF;}#mermaid-svg text.actor&gt;tspan{fill:black;stroke:none;}#mermaid-svg .actor-line{stroke:grey;}#mermaid-svg .messageLine0{stroke-width:1.5;stroke-dasharray:none;stroke:#333;}#mermaid-svg .messageLine1{stroke-width:1.5;stroke-dasharray:2,2;stroke:#333;}#mermaid-svg #arrowhead path{fill:#333;stroke:#333;}#mermaid-svg .sequenceNumber{fill:white;}#mermaid-svg #sequencenumber{fill:#333;}#mermaid-svg #crosshead path{fill:#333;stroke:#333;}#mermaid-svg .messageText{fill:#333;stroke:none;}#mermaid-svg .labelBox{stroke:hsl(259.6261682243, 59.7765363128%, 87.9019607843%);fill:#ECECFF;}#mermaid-svg .labelText,#mermaid-svg .labelText&gt;tspan{fill:black;stroke:none;}#mermaid-svg .loopText,#mermaid-svg .loopText&gt;tspan{fill:black;stroke:none;}#mermaid-svg .loopLine{stroke-width:2px;stroke-dasharray:2,2;stroke:hsl(259.6261682243, 59.7765363128%, 87.9019607843%);fill:hsl(259.6261682243, 59.7765363128%, 87.9019607843%);}#mermaid-svg .note{stroke:#aaaa33;fill:#fff5ad;}#mermaid-svg .noteText,#mermaid-svg .noteText&gt;tspan{fill:black;stroke:none;}#mermaid-svg .activation0{fill:#f4f4f4;stroke:#666;}#mermaid-svg .activation1{fill:#f4f4f4;stroke:#666;}#mermaid-svg .activation2{fill:#f4f4f4;stroke:#666;}#mermaid-svg .actorPopupMenu{position:absolute;}#mermaid-svg .actorPopupMenuPanel{position:absolute;fill:#ECECFF;box-shadow:0px 8px 16px 0px rgba(0,0,0,0.2);filter:drop-shadow(3px 5px 2px rgb(0 0 0 / 0.4));}#mermaid-svg .actor-man line{stroke:hsl(259.6261682243, 59.7765363128%, 87.9019607843%);fill:#ECECFF;}#mermaid-svg .actor-man circle,#mermaid-svg line{stroke:hsl(259.6261682243, 59.7765363128%, 87.9019607843%);fill:#ECECFF;stroke-width:2px;}#mermaid-svg :root{--mermaid-font-family:\"trebuchet ms\",verdana,arial,sans-serif;}</style><g/><defs><symbol id=\"computer\" width=\"24\" height=\"24\"><path transform=\"scale(.5)\" d=\"M2 2v13h20v-13h-20zm18 11h-16v-9h16v9zm-10.228 6l.466-1h3.524l.467 1h-4.457zm14.228 3h-24l2-6h2.104l-1.33 4h18.45l-1.297-4h2.073l2 6zm-5-10h-14v-7h14v7z\"/></symbol></defs><defs><symbol id=\"database\" fill-rule=\"evenodd\" clip-rule=\"evenodd\"><path transform=\"scale(.5)\" d=\"M12.258.001l.256.004.255.005.253.008.251.01.249.012.247.015.246.016.242.019.241.02.239.023.236.024.233.027.231.028.229.031.225.032.223.034.22.036.217.038.214.04.211.041.208.043.205.045.201.046.198.048.194.05.191.051.187.053.183.054.18.056.175.057.172.059.168.06.163.061.16.063.155.064.15.066.074.033.073.033.071.034.07.034.069.035.068.035.067.035.066.035.064.036.064.036.062.036.06.036.06.037.058.037.058.037.055.038.055.038.053.038.052.038.051.039.05.039.048.039.047.039.045.04.044.04.043.04.041.04.04.041.039.041.037.041.036.041.034.041.033.042.032.042.03.042.029.042.027.042.026.043.024.043.023.043.021.043.02.043.018.044.017.043.015.044.013.044.012.044.011.045.009.044.007.045.006.045.004.045.002.045.001.045v17l-.001.045-.002.045-.004.045-.006.045-.007.045-.009.044-.011.045-.012.044-.013.044-.015.044-.017.043-.018.044-.02.043-.021.043-.023.043-.024.043-.026.043-.027.042-.029.042-.03.042-.032.042-.033.042-.034.041-.036.041-.037.041-.039.041-.04.041-.041.04-.043.04-.044.04-.045.04-.047.039-.048.039-.05.039-.051.039-.052.038-.053.038-.055.038-.055.038-.058.037-.058.037-.06.037-.06.036-.062.036-.064.036-.064.036-.066.035-.067.035-.068.035-.069.035-.07.034-.071.034-.073.033-.074.033-.15.066-.155.064-.16.063-.163.061-.168.06-.172.059-.175.057-.18.056-.183.054-.187.053-.191.051-.194.05-.198.048-.201.046-.205.045-.208.043-.211.041-.214.04-.217.038-.22.036-.223.034-.225.032-.229.031-.231.028-.233.027-.236.024-.239.023-.241.02-.242.019-.246.016-.247.015-.249.012-.251.01-.253.008-.255.005-.256.004-.258.001-.258-.001-.256-.004-.255-.005-.253-.008-.251-.01-.249-.012-.247-.015-.245-.016-.243-.019-.241-.02-.238-.023-.236-.024-.234-.027-.231-.028-.228-.031-.226-.032-.223-.034-.22-.036-.217-.038-.214-.04-.211-.041-.208-.043-.204-.045-.201-.046-.198-.048-.195-.05-.19-.051-.187-.053-.184-.054-.179-.056-.176-.057-.172-.059-.167-.06-.164-.061-.159-.063-.155-.064-.151-.066-.074-.033-.072-.033-.072-.034-.07-.034-.069-.035-.068-.035-.067-.035-.066-.035-.064-.036-.063-.036-.062-.036-.061-.036-.06-.037-.058-.037-.057-.037-.056-.038-.055-.038-.053-.038-.052-.038-.051-.039-.049-.039-.049-.039-.046-.039-.046-.04-.044-.04-.043-.04-.041-.04-.04-.041-.039-.041-.037-.041-.036-.041-.034-.041-.033-.042-.032-.042-.03-.042-.029-.042-.027-.042-.026-.043-.024-.043-.023-.043-.021-.043-.02-.043-.018-.044-.017-.043-.015-.044-.013-.044-.012-.044-.011-.045-.009-.044-.007-.045-.006-.045-.004-.045-.002-.045-.001-.045v-17l.001-.045.002-.045.004-.045.006-.045.007-.045.009-.044.011-.045.012-.044.013-.044.015-.044.017-.043.018-.044.02-.043.021-.043.023-.043.024-.043.026-.043.027-.042.029-.042.03-.042.032-.042.033-.042.034-.041.036-.041.037-.041.039-.041.04-.041.041-.04.043-.04.044-.04.046-.04.046-.039.049-.039.049-.039.051-.039.052-.038.053-.038.055-.038.056-.038.057-.037.058-.037.06-.037.061-.036.062-.036.063-.036.064-.036.066-.035.067-.035.068-.035.069-.035.07-.034.072-.034.072-.033.074-.033.151-.066.155-.064.159-.063.164-.061.167-.06.172-.059.176-.057.179-.056.184-.054.187-.053.19-.051.195-.05.198-.048.201-.046.204-.045.208-.043.211-.041.214-.04.217-.038.22-.036.223-.034.226-.032.228-.031.231-.028.234-.027.236-.024.238-.023.241-.02.243-.019.245-.016.247-.015.249-.012.251-.01.253-.008.255-.005.256-.004.258-.001.258.001zm-9.258 20.499v.01l.001.021.003.021.004.022.005.021.006.022.007.022.009.023.01.022.011.023.012.023.013.023.015.023.016.024.017.023.018.024.019.024.021.024.022.025.023.024.024.025.052.049.056.05.061.051.066.051.07.051.075.051.079.052.084.052.088.052.092.052.097.052.102.051.105.052.11.052.114.051.119.051.123.051.127.05.131.05.135.05.139.048.144.049.147.047.152.047.155.047.16.045.163.045.167.043.171.043.176.041.178.041.183.039.187.039.19.037.194.035.197.035.202.033.204.031.209.03.212.029.216.027.219.025.222.024.226.021.23.02.233.018.236.016.24.015.243.012.246.01.249.008.253.005.256.004.259.001.26-.001.257-.004.254-.005.25-.008.247-.011.244-.012.241-.014.237-.016.233-.018.231-.021.226-.021.224-.024.22-.026.216-.027.212-.028.21-.031.205-.031.202-.034.198-.034.194-.036.191-.037.187-.039.183-.04.179-.04.175-.042.172-.043.168-.044.163-.045.16-.046.155-.046.152-.047.148-.048.143-.049.139-.049.136-.05.131-.05.126-.05.123-.051.118-.052.114-.051.11-.052.106-.052.101-.052.096-.052.092-.052.088-.053.083-.051.079-.052.074-.052.07-.051.065-.051.06-.051.056-.05.051-.05.023-.024.023-.025.021-.024.02-.024.019-.024.018-.024.017-.024.015-.023.014-.024.013-.023.012-.023.01-.023.01-.022.008-.022.006-.022.006-.022.004-.022.004-.021.001-.021.001-.021v-4.127l-.077.055-.08.053-.083.054-.085.053-.087.052-.09.052-.093.051-.095.05-.097.05-.1.049-.102.049-.105.048-.106.047-.109.047-.111.046-.114.045-.115.045-.118.044-.12.043-.122.042-.124.042-.126.041-.128.04-.13.04-.132.038-.134.038-.135.037-.138.037-.139.035-.142.035-.143.034-.144.033-.147.032-.148.031-.15.03-.151.03-.153.029-.154.027-.156.027-.158.026-.159.025-.161.024-.162.023-.163.022-.165.021-.166.02-.167.019-.169.018-.169.017-.171.016-.173.015-.173.014-.175.013-.175.012-.177.011-.178.01-.179.008-.179.008-.181.006-.182.005-.182.004-.184.003-.184.002h-.37l-.184-.002-.184-.003-.182-.004-.182-.005-.181-.006-.179-.008-.179-.008-.178-.01-.176-.011-.176-.012-.175-.013-.173-.014-.172-.015-.171-.016-.17-.017-.169-.018-.167-.019-.166-.02-.165-.021-.163-.022-.162-.023-.161-.024-.159-.025-.157-.026-.156-.027-.155-.027-.153-.029-.151-.03-.15-.03-.148-.031-.146-.032-.145-.033-.143-.034-.141-.035-.14-.035-.137-.037-.136-.037-.134-.038-.132-.038-.13-.04-.128-.04-.126-.041-.124-.042-.122-.042-.12-.044-.117-.043-.116-.045-.113-.045-.112-.046-.109-.047-.106-.047-.105-.048-.102-.049-.1-.049-.097-.05-.095-.05-.093-.052-.09-.051-.087-.052-.085-.053-.083-.054-.08-.054-.077-.054v4.127zm0-5.654v.011l.001.021.003.021.004.021.005.022.006.022.007.022.009.022.01.022.011.023.012.023.013.023.015.024.016.023.017.024.018.024.019.024.021.024.022.024.023.025.024.024.052.05.056.05.061.05.066.051.07.051.075.052.079.051.084.052.088.052.092.052.097.052.102.052.105.052.11.051.114.051.119.052.123.05.127.051.131.05.135.049.139.049.144.048.147.048.152.047.155.046.16.045.163.045.167.044.171.042.176.042.178.04.183.04.187.038.19.037.194.036.197.034.202.033.204.032.209.03.212.028.216.027.219.025.222.024.226.022.23.02.233.018.236.016.24.014.243.012.246.01.249.008.253.006.256.003.259.001.26-.001.257-.003.254-.006.25-.008.247-.01.244-.012.241-.015.237-.016.233-.018.231-.02.226-.022.224-.024.22-.025.216-.027.212-.029.21-.03.205-.032.202-.033.198-.035.194-.036.191-.037.187-.039.183-.039.179-.041.175-.042.172-.043.168-.044.163-.045.16-.045.155-.047.152-.047.148-.048.143-.048.139-.05.136-.049.131-.05.126-.051.123-.051.118-.051.114-.052.11-.052.106-.052.101-.052.096-.052.092-.052.088-.052.083-.052.079-.052.074-.051.07-.052.065-.051.06-.05.056-.051.051-.049.023-.025.023-.024.021-.025.02-.024.019-.024.018-.024.017-.024.015-.023.014-.023.013-.024.012-.022.01-.023.01-.023.008-.022.006-.022.006-.022.004-.021.004-.022.001-.021.001-.021v-4.139l-.077.054-.08.054-.083.054-.085.052-.087.053-.09.051-.093.051-.095.051-.097.05-.1.049-.102.049-.105.048-.106.047-.109.047-.111.046-.114.045-.115.044-.118.044-.12.044-.122.042-.124.042-.126.041-.128.04-.13.039-.132.039-.134.038-.135.037-.138.036-.139.036-.142.035-.143.033-.144.033-.147.033-.148.031-.15.03-.151.03-.153.028-.154.028-.156.027-.158.026-.159.025-.161.024-.162.023-.163.022-.165.021-.166.02-.167.019-.169.018-.169.017-.171.016-.173.015-.173.014-.175.013-.175.012-.177.011-.178.009-.179.009-.179.007-.181.007-.182.005-.182.004-.184.003-.184.002h-.37l-.184-.002-.184-.003-.182-.004-.182-.005-.181-.007-.179-.007-.179-.009-.178-.009-.176-.011-.176-.012-.175-.013-.173-.014-.172-.015-.171-.016-.17-.017-.169-.018-.167-.019-.166-.02-.165-.021-.163-.022-.162-.023-.161-.024-.159-.025-.157-.026-.156-.027-.155-.028-.153-.028-.151-.03-.15-.03-.148-.031-.146-.033-.145-.033-.143-.033-.141-.035-.14-.036-.137-.036-.136-.037-.134-.038-.132-.039-.13-.039-.128-.04-.126-.041-.124-.042-.122-.043-.12-.043-.117-.044-.116-.044-.113-.046-.112-.046-.109-.046-.106-.047-.105-.048-.102-.049-.1-.049-.097-.05-.095-.051-.093-.051-.09-.051-.087-.053-.085-.052-.083-.054-.08-.054-.077-.054v4.139zm0-5.666v.011l.001.02.003.022.004.021.005.022.006.021.007.022.009.023.01.022.011.023.012.023.013.023.015.023.016.024.017.024.018.023.019.024.021.025.022.024.023.024.024.025.052.05.056.05.061.05.066.051.07.051.075.052.079.051.084.052.088.052.092.052.097.052.102.052.105.051.11.052.114.051.119.051.123.051.127.05.131.05.135.05.139.049.144.048.147.048.152.047.155.046.16.045.163.045.167.043.171.043.176.042.178.04.183.04.187.038.19.037.194.036.197.034.202.033.204.032.209.03.212.028.216.027.219.025.222.024.226.021.23.02.233.018.236.017.24.014.243.012.246.01.249.008.253.006.256.003.259.001.26-.001.257-.003.254-.006.25-.008.247-.01.244-.013.241-.014.237-.016.233-.018.231-.02.226-.022.224-.024.22-.025.216-.027.212-.029.21-.03.205-.032.202-.033.198-.035.194-.036.191-.037.187-.039.183-.039.179-.041.175-.042.172-.043.168-.044.163-.045.16-.045.155-.047.152-.047.148-.048.143-.049.139-.049.136-.049.131-.051.126-.05.123-.051.118-.052.114-.051.11-.052.106-.052.101-.052.096-.052.092-.052.088-.052.083-.052.079-.052.074-.052.07-.051.065-.051.06-.051.056-.05.051-.049.023-.025.023-.025.021-.024.02-.024.019-.024.018-.024.017-.024.015-.023.014-.024.013-.023.012-.023.01-.022.01-.023.008-.022.006-.022.006-.022.004-.022.004-.021.001-.021.001-.021v-4.153l-.077.054-.08.054-.083.053-.085.053-.087.053-.09.051-.093.051-.095.051-.097.05-.1.049-.102.048-.105.048-.106.048-.109.046-.111.046-.114.046-.115.044-.118.044-.12.043-.122.043-.124.042-.126.041-.128.04-.13.039-.132.039-.134.038-.135.037-.138.036-.139.036-.142.034-.143.034-.144.033-.147.032-.148.032-.15.03-.151.03-.153.028-.154.028-.156.027-.158.026-.159.024-.161.024-.162.023-.163.023-.165.021-.166.02-.167.019-.169.018-.169.017-.171.016-.173.015-.173.014-.175.013-.175.012-.177.01-.178.01-.179.009-.179.007-.181.006-.182.006-.182.004-.184.003-.184.001-.185.001-.185-.001-.184-.001-.184-.003-.182-.004-.182-.006-.181-.006-.179-.007-.179-.009-.178-.01-.176-.01-.176-.012-.175-.013-.173-.014-.172-.015-.171-.016-.17-.017-.169-.018-.167-.019-.166-.02-.165-.021-.163-.023-.162-.023-.161-.024-.159-.024-.157-.026-.156-.027-.155-.028-.153-.028-.151-.03-.15-.03-.148-.032-.146-.032-.145-.033-.143-.034-.141-.034-.14-.036-.137-.036-.136-.037-.134-.038-.132-.039-.13-.039-.128-.041-.126-.041-.124-.041-.122-.043-.12-.043-.117-.044-.116-.044-.113-.046-.112-.046-.109-.046-.106-.048-.105-.048-.102-.048-.1-.05-.097-.049-.095-.051-.093-.051-.09-.052-.087-.052-.085-.053-.083-.053-.08-.054-.077-.054v4.153zm8.74-8.179l-.257.004-.254.005-.25.008-.247.011-.244.012-.241.014-.237.016-.233.018-.231.021-.226.022-.224.023-.22.026-.216.027-.212.028-.21.031-.205.032-.202.033-.198.034-.194.036-.191.038-.187.038-.183.04-.179.041-.175.042-.172.043-.168.043-.163.045-.16.046-.155.046-.152.048-.148.048-.143.048-.139.049-.136.05-.131.05-.126.051-.123.051-.118.051-.114.052-.11.052-.106.052-.101.052-.096.052-.092.052-.088.052-.083.052-.079.052-.074.051-.07.052-.065.051-.06.05-.056.05-.051.05-.023.025-.023.024-.021.024-.02.025-.019.024-.018.024-.017.023-.015.024-.014.023-.013.023-.012.023-.01.023-.01.022-.008.022-.006.023-.006.021-.004.022-.004.021-.001.021-.001.021.001.021.001.021.004.021.004.022.006.021.006.023.008.022.01.022.01.023.012.023.013.023.014.023.015.024.017.023.018.024.019.024.02.025.021.024.023.024.023.025.051.05.056.05.06.05.065.051.07.052.074.051.079.052.083.052.088.052.092.052.096.052.101.052.106.052.11.052.114.052.118.051.123.051.126.051.131.05.136.05.139.049.143.048.148.048.152.048.155.046.16.046.163.045.168.043.172.043.175.042.179.041.183.04.187.038.191.038.194.036.198.034.202.033.205.032.21.031.212.028.216.027.22.026.224.023.226.022.231.021.233.018.237.016.241.014.244.012.247.011.25.008.254.005.257.004.26.001.26-.001.257-.004.254-.005.25-.008.247-.011.244-.012.241-.014.237-.016.233-.018.231-.021.226-.022.224-.023.22-.026.216-.027.212-.028.21-.031.205-.032.202-.033.198-.034.194-.036.191-.038.187-.038.183-.04.179-.041.175-.042.172-.043.168-.043.163-.045.16-.046.155-.046.152-.048.148-.048.143-.048.139-.049.136-.05.131-.05.126-.051.123-.051.118-.051.114-.052.11-.052.106-.052.101-.052.096-.052.092-.052.088-.052.083-.052.079-.052.074-.051.07-.052.065-.051.06-.05.056-.05.051-.05.023-.025.023-.024.021-.024.02-.025.019-.024.018-.024.017-.023.015-.024.014-.023.013-.023.012-.023.01-.023.01-.022.008-.022.006-.023.006-.021.004-.022.004-.021.001-.021.001-.021-.001-.021-.001-.021-.004-.021-.004-.022-.006-.021-.006-.023-.008-.022-.01-.022-.01-.023-.012-.023-.013-.023-.014-.023-.015-.024-.017-.023-.018-.024-.019-.024-.02-.025-.021-.024-.023-.024-.023-.025-.051-.05-.056-.05-.06-.05-.065-.051-.07-.052-.074-.051-.079-.052-.083-.052-.088-.052-.092-.052-.096-.052-.101-.052-.106-.052-.11-.052-.114-.052-.118-.051-.123-.051-.126-.051-.131-.05-.136-.05-.139-.049-.143-.048-.148-.048-.152-.048-.155-.046-.16-.046-.163-.045-.168-.043-.172-.043-.175-.042-.179-.041-.183-.04-.187-.038-.191-.038-.194-.036-.198-.034-.202-.033-.205-.032-.21-.031-.212-.028-.216-.027-.22-.026-.224-.023-.226-.022-.231-.021-.233-.018-.237-.016-.241-.014-.244-.012-.247-.011-.25-.008-.254-.005-.257-.004-.26-.001-.26.001z\"/></symbol></defs><defs><symbol id=\"clock\" width=\"24\" height=\"24\"><path transform=\"scale(.5)\" d=\"M12 2c5.514 0 10 4.486 10 10s-4.486 10-10 10-10-4.486-10-10 4.486-10 10-10zm0-2c-6.627 0-12 5.373-12 12s5.373 12 12 12 12-5.373 12-12-5.373-12-12-12zm5.848 12.459c.202.038.202.333.001.372-1.907.361-6.045 1.111-6.547 1.111-.719 0-1.301-.582-1.301-1.301 0-.512.77-5.447 1.125-7.445.034-.192.312-.181.343.014l.985 6.238 5.394 1.011z\"/></symbol></defs><defs><marker id=\"arrowhead\" refX=\"7.9\" refY=\"5\" markerUnits=\"userSpaceOnUse\" markerWidth=\"12\" markerHeight=\"12\" orient=\"auto\"><path d=\"M 0 0 L 10 5 L 0 10 z\"/></marker></defs><defs><marker id=\"crosshead\" markerWidth=\"15\" markerHeight=\"8\" orient=\"auto\" refX=\"4\" refY=\"4.5\"><path fill=\"none\" stroke=\"#000000\" stroke-width=\"1pt\" d=\"M 1,2 L 6,7 M 6,2 L 1,7\" style=\"stroke-dasharray: 0, 0;\"/></marker></defs><defs><marker id=\"filled-head\" refX=\"15.5\" refY=\"7\" markerWidth=\"20\" markerHeight=\"28\" orient=\"auto\"><path d=\"M 18,7 L9,13 L14,7 L9,1 Z\"/></marker></defs><defs><marker id=\"sequencenumber\" refX=\"15\" refY=\"15\" markerWidth=\"60\" markerHeight=\"40\" orient=\"auto\"><circle cx=\"15\" cy=\"15\" r=\"6\"/></marker></defs><text x=\"174\" y=\"80\" text-anchor=\"middle\" dominant-baseline=\"middle\" alignment-baseline=\"middle\" class=\"messageText\" dy=\"1em\" style=\"font-size: 16px; font-weight: 400;\">prompt</text><text x=\"174\" y=\"99\" text-anchor=\"middle\" dominant-baseline=\"middle\" alignment-baseline=\"middle\" class=\"messageText\" dy=\"1em\" style=\"font-size: 16px; font-weight: 400;\">conf spec</text><line x1=\"76\" y1=\"129\" x2=\"271\" y2=\"129\" class=\"messageLine0\" stroke-width=\"2\" stroke=\"none\" marker-end=\"url(#arrowhead)\" style=\"fill: none;\"/><text x=\"374\" y=\"144\" text-anchor=\"middle\" dominant-baseline=\"middle\" alignment-baseline=\"middle\" class=\"messageText\" dy=\"1em\" style=\"font-size: 16px; font-weight: 400;\">conf spec</text><line x1=\"276\" y1=\"175\" x2=\"471\" y2=\"175\" class=\"messageLine0\" stroke-width=\"2\" stroke=\"none\" marker-end=\"url(#arrowhead)\" style=\"fill: none;\"/><text x=\"574\" y=\"190\" text-anchor=\"middle\" dominant-baseline=\"middle\" alignment-baseline=\"middle\" class=\"messageText\" dy=\"1em\" style=\"font-size: 16px; font-weight: 400;\">conf spec</text><line x1=\"476\" y1=\"221\" x2=\"671\" y2=\"221\" class=\"messageLine0\" stroke-width=\"2\" stroke=\"none\" marker-end=\"url(#arrowhead)\" style=\"fill: none;\"/><text x=\"774\" y=\"236\" text-anchor=\"middle\" dominant-baseline=\"middle\" alignment-baseline=\"middle\" class=\"messageText\" dy=\"1em\" style=\"font-size: 16px; font-weight: 400;\">wrap with</text><line x1=\"676\" y1=\"267\" x2=\"871\" y2=\"267\" class=\"messageLine0\" stroke-width=\"2\" stroke=\"none\" marker-end=\"url(#arrowhead)\" style=\"fill: none;\"/><text x=\"577\" y=\"282\" text-anchor=\"middle\" dominant-baseline=\"middle\" alignment-baseline=\"middle\" class=\"messageText\" dy=\"1em\" style=\"font-size: 16px; font-weight: 400;\">evaluator object</text><line x1=\"874\" y1=\"313\" x2=\"279\" y2=\"313\" class=\"messageLine0\" stroke-width=\"2\" stroke=\"none\" marker-end=\"url(#arrowhead)\" style=\"fill: none;\"/><text x=\"675\" y=\"328\" text-anchor=\"middle\" dominant-baseline=\"middle\" alignment-baseline=\"middle\" class=\"messageText\" dy=\"1em\" style=\"font-size: 16px; font-weight: 400;\">create with:</text><text x=\"675\" y=\"347\" text-anchor=\"middle\" dominant-baseline=\"middle\" alignment-baseline=\"middle\" class=\"messageText\" dy=\"1em\" style=\"font-size: 16px; font-weight: 400;\">evaluator object</text><text x=\"675\" y=\"366\" text-anchor=\"middle\" dominant-baseline=\"middle\" alignment-baseline=\"middle\" class=\"messageText\" dy=\"1em\" style=\"font-size: 16px; font-weight: 400;\">prompt</text><line x1=\"276\" y1=\"393.6666666666667\" x2=\"1074\" y2=\"393.6666666666667\" class=\"messageLine0\" stroke-width=\"2\" stroke=\"none\" marker-end=\"url(#arrowhead)\" style=\"fill: none;\"/><text x=\"678\" y=\"409\" text-anchor=\"middle\" dominant-baseline=\"middle\" alignment-baseline=\"middle\" class=\"messageText\" dy=\"1em\" style=\"font-size: 16px; font-weight: 400;\">handle</text><line x1=\"1077\" y1=\"437.6666666666667\" x2=\"279\" y2=\"437.6666666666667\" class=\"messageLine0\" stroke-width=\"2\" stroke=\"none\" marker-end=\"url(#arrowhead)\" style=\"fill: none;\"/><text x=\"177\" y=\"453\" text-anchor=\"middle\" dominant-baseline=\"middle\" alignment-baseline=\"middle\" class=\"messageText\" dy=\"1em\" style=\"font-size: 16px; font-weight: 400;\">handle</text><line x1=\"274\" y1=\"481.6666666666667\" x2=\"79\" y2=\"481.6666666666667\" class=\"messageLine0\" stroke-width=\"2\" stroke=\"none\" marker-end=\"url(#arrowhead)\" style=\"fill: none;\"/></svg>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#% mermaid\n",
    "sequenceDiagram\n",
    "  participant User\n",
    "  participant llmfunc as llm-function\n",
    "  participant llmconf as llm-configuration\n",
    "  participant LLMConf as LLM configuration\n",
    "  participant LLMEval as LLM evaluator\n",
    "  participant AnonFunc as Anonymous function\n",
    "  User ->> llmfunc: prompt<br>conf spec\n",
    "  llmfunc ->> llmconf: conf spec\n",
    "  llmconf ->> LLMConf: conf spec\n",
    "  LLMConf ->> LLMEval: wrap with\n",
    "  LLMEval ->> llmfunc: evaluator object\n",
    "  llmfunc ->> AnonFunc:  create with:<br>evaluator object<br>prompt\n",
    "  AnonFunc ->> llmfunc: handle\n",
    "  llmfunc ->> User: handle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a sequence diagram for making a LLM configuration with a global (engineered) prompt, and using that configuration to generate a chat message response:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<svg id=\"mermaid-svg\" width=\"100%\" xmlns=\"http://www.w3.org/2000/svg\" style=\"max-width: 1456px; background-color: rgb(255, 255, 255);\" viewBox=\"-50 -10 1456 760.1666666666667\" role=\"graphics-document document\" aria-roledescription=\"sequence\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><style xmlns=\"http://www.w3.org/1999/xhtml\">@import url(\"https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.2/css/all.min.css\");</style><g><rect x=\"1200\" y=\"674.1666666666667\" fill=\"#eaeaea\" stroke=\"#666\" width=\"156\" height=\"65\" name=\"AnonFunc\" rx=\"3\" ry=\"3\" class=\"actor actor-bottom\"/><text x=\"1278\" y=\"706.6666666666667\" dominant-baseline=\"central\" alignment-baseline=\"central\" class=\"actor\" style=\"text-anchor: middle; font-size: 16px; font-weight: 400;\"><tspan x=\"1278\" dy=\"0\">Anonymous function</tspan></text></g><g><rect x=\"1000\" y=\"674.1666666666667\" fill=\"#eaeaea\" stroke=\"#666\" width=\"150\" height=\"65\" name=\"LLMChatEval\" rx=\"3\" ry=\"3\" class=\"actor actor-bottom\"/><text x=\"1075\" y=\"706.6666666666667\" dominant-baseline=\"central\" alignment-baseline=\"central\" class=\"actor\" style=\"text-anchor: middle; font-size: 16px; font-weight: 400;\"><tspan x=\"1075\" dy=\"0\">LLM chat evaluator</tspan></text></g><g><rect x=\"800\" y=\"674.1666666666667\" fill=\"#eaeaea\" stroke=\"#666\" width=\"150\" height=\"65\" name=\"LLMConf\" rx=\"3\" ry=\"3\" class=\"actor actor-bottom\"/><text x=\"875\" y=\"706.6666666666667\" dominant-baseline=\"central\" alignment-baseline=\"central\" class=\"actor\" style=\"text-anchor: middle; font-size: 16px; font-weight: 400;\"><tspan x=\"875\" dy=\"0\">LLM configuration</tspan></text></g><g><rect x=\"600\" y=\"674.1666666666667\" fill=\"#eaeaea\" stroke=\"#666\" width=\"150\" height=\"65\" name=\"llmconf\" rx=\"3\" ry=\"3\" class=\"actor actor-bottom\"/><text x=\"675\" y=\"706.6666666666667\" dominant-baseline=\"central\" alignment-baseline=\"central\" class=\"actor\" style=\"text-anchor: middle; font-size: 16px; font-weight: 400;\"><tspan x=\"675\" dy=\"0\">llm-configuration</tspan></text></g><g><rect x=\"400\" y=\"674.1666666666667\" fill=\"#eaeaea\" stroke=\"#666\" width=\"150\" height=\"65\" name=\"llmfunc\" rx=\"3\" ry=\"3\" class=\"actor actor-bottom\"/><text x=\"475\" y=\"706.6666666666667\" dominant-baseline=\"central\" alignment-baseline=\"central\" class=\"actor\" style=\"text-anchor: middle; font-size: 16px; font-weight: 400;\"><tspan x=\"475\" dy=\"0\">llm-function</tspan></text></g><g><rect x=\"200\" y=\"674.1666666666667\" fill=\"#eaeaea\" stroke=\"#666\" width=\"150\" height=\"65\" name=\"User\" rx=\"3\" ry=\"3\" class=\"actor actor-bottom\"/><text x=\"275\" y=\"706.6666666666667\" dominant-baseline=\"central\" alignment-baseline=\"central\" class=\"actor\" style=\"text-anchor: middle; font-size: 16px; font-weight: 400;\"><tspan x=\"275\" dy=\"0\">User</tspan></text></g><g><rect x=\"0\" y=\"674.1666666666667\" fill=\"#eaeaea\" stroke=\"#666\" width=\"150\" height=\"65\" name=\"WWWOpenAI\" rx=\"3\" ry=\"3\" class=\"actor actor-bottom\"/><text x=\"75\" y=\"706.6666666666667\" dominant-baseline=\"central\" alignment-baseline=\"central\" class=\"actor\" style=\"text-anchor: middle; font-size: 16px; font-weight: 400;\"><tspan x=\"75\" dy=\"0\">WWW::OpenAI</tspan></text></g><g><line id=\"actor6\" x1=\"1278\" y1=\"5\" x2=\"1278\" y2=\"674.1666666666667\" class=\"200\" stroke-width=\"0.5px\" stroke=\"#999\"/><g id=\"root-6\"><rect x=\"1200\" y=\"0\" fill=\"#eaeaea\" stroke=\"#666\" width=\"156\" height=\"65\" name=\"AnonFunc\" rx=\"3\" ry=\"3\" class=\"actor actor-top\"/><text x=\"1278\" y=\"32.5\" dominant-baseline=\"central\" alignment-baseline=\"central\" class=\"actor\" style=\"text-anchor: middle; font-size: 16px; font-weight: 400;\"><tspan x=\"1278\" dy=\"0\">Anonymous function</tspan></text></g></g><g><line id=\"actor5\" x1=\"1075\" y1=\"5\" x2=\"1075\" y2=\"674.1666666666667\" class=\"200\" stroke-width=\"0.5px\" stroke=\"#999\"/><g id=\"root-5\"><rect x=\"1000\" y=\"0\" fill=\"#eaeaea\" stroke=\"#666\" width=\"150\" height=\"65\" name=\"LLMChatEval\" rx=\"3\" ry=\"3\" class=\"actor actor-top\"/><text x=\"1075\" y=\"32.5\" dominant-baseline=\"central\" alignment-baseline=\"central\" class=\"actor\" style=\"text-anchor: middle; font-size: 16px; font-weight: 400;\"><tspan x=\"1075\" dy=\"0\">LLM chat evaluator</tspan></text></g></g><g><line id=\"actor4\" x1=\"875\" y1=\"5\" x2=\"875\" y2=\"674.1666666666667\" class=\"200\" stroke-width=\"0.5px\" stroke=\"#999\"/><g id=\"root-4\"><rect x=\"800\" y=\"0\" fill=\"#eaeaea\" stroke=\"#666\" width=\"150\" height=\"65\" name=\"LLMConf\" rx=\"3\" ry=\"3\" class=\"actor actor-top\"/><text x=\"875\" y=\"32.5\" dominant-baseline=\"central\" alignment-baseline=\"central\" class=\"actor\" style=\"text-anchor: middle; font-size: 16px; font-weight: 400;\"><tspan x=\"875\" dy=\"0\">LLM configuration</tspan></text></g></g><g><line id=\"actor3\" x1=\"675\" y1=\"5\" x2=\"675\" y2=\"674.1666666666667\" class=\"200\" stroke-width=\"0.5px\" stroke=\"#999\"/><g id=\"root-3\"><rect x=\"600\" y=\"0\" fill=\"#eaeaea\" stroke=\"#666\" width=\"150\" height=\"65\" name=\"llmconf\" rx=\"3\" ry=\"3\" class=\"actor actor-top\"/><text x=\"675\" y=\"32.5\" dominant-baseline=\"central\" alignment-baseline=\"central\" class=\"actor\" style=\"text-anchor: middle; font-size: 16px; font-weight: 400;\"><tspan x=\"675\" dy=\"0\">llm-configuration</tspan></text></g></g><g><line id=\"actor2\" x1=\"475\" y1=\"5\" x2=\"475\" y2=\"674.1666666666667\" class=\"200\" stroke-width=\"0.5px\" stroke=\"#999\"/><g id=\"root-2\"><rect x=\"400\" y=\"0\" fill=\"#eaeaea\" stroke=\"#666\" width=\"150\" height=\"65\" name=\"llmfunc\" rx=\"3\" ry=\"3\" class=\"actor actor-top\"/><text x=\"475\" y=\"32.5\" dominant-baseline=\"central\" alignment-baseline=\"central\" class=\"actor\" style=\"text-anchor: middle; font-size: 16px; font-weight: 400;\"><tspan x=\"475\" dy=\"0\">llm-function</tspan></text></g></g><g><line id=\"actor1\" x1=\"275\" y1=\"5\" x2=\"275\" y2=\"674.1666666666667\" class=\"200\" stroke-width=\"0.5px\" stroke=\"#999\"/><g id=\"root-1\"><rect x=\"200\" y=\"0\" fill=\"#eaeaea\" stroke=\"#666\" width=\"150\" height=\"65\" name=\"User\" rx=\"3\" ry=\"3\" class=\"actor actor-top\"/><text x=\"275\" y=\"32.5\" dominant-baseline=\"central\" alignment-baseline=\"central\" class=\"actor\" style=\"text-anchor: middle; font-size: 16px; font-weight: 400;\"><tspan x=\"275\" dy=\"0\">User</tspan></text></g></g><g><line id=\"actor0\" x1=\"75\" y1=\"5\" x2=\"75\" y2=\"674.1666666666667\" class=\"200\" stroke-width=\"0.5px\" stroke=\"#999\"/><g id=\"root-0\"><rect x=\"0\" y=\"0\" fill=\"#eaeaea\" stroke=\"#666\" width=\"150\" height=\"65\" name=\"WWWOpenAI\" rx=\"3\" ry=\"3\" class=\"actor actor-top\"/><text x=\"75\" y=\"32.5\" dominant-baseline=\"central\" alignment-baseline=\"central\" class=\"actor\" style=\"text-anchor: middle; font-size: 16px; font-weight: 400;\"><tspan x=\"75\" dy=\"0\">WWW::OpenAI</tspan></text></g></g><style>#mermaid-svg{font-family:\"trebuchet ms\",verdana,arial,sans-serif;font-size:16px;fill:#333;}#mermaid-svg .error-icon{fill:#552222;}#mermaid-svg .error-text{fill:#552222;stroke:#552222;}#mermaid-svg .edge-thickness-normal{stroke-width:2px;}#mermaid-svg .edge-thickness-thick{stroke-width:3.5px;}#mermaid-svg .edge-pattern-solid{stroke-dasharray:0;}#mermaid-svg .edge-pattern-dashed{stroke-dasharray:3;}#mermaid-svg .edge-pattern-dotted{stroke-dasharray:2;}#mermaid-svg .marker{fill:#333333;stroke:#333333;}#mermaid-svg .marker.cross{stroke:#333333;}#mermaid-svg svg{font-family:\"trebuchet ms\",verdana,arial,sans-serif;font-size:16px;}#mermaid-svg .actor{stroke:hsl(259.6261682243, 59.7765363128%, 87.9019607843%);fill:#ECECFF;}#mermaid-svg text.actor&gt;tspan{fill:black;stroke:none;}#mermaid-svg .actor-line{stroke:grey;}#mermaid-svg .messageLine0{stroke-width:1.5;stroke-dasharray:none;stroke:#333;}#mermaid-svg .messageLine1{stroke-width:1.5;stroke-dasharray:2,2;stroke:#333;}#mermaid-svg #arrowhead path{fill:#333;stroke:#333;}#mermaid-svg .sequenceNumber{fill:white;}#mermaid-svg #sequencenumber{fill:#333;}#mermaid-svg #crosshead path{fill:#333;stroke:#333;}#mermaid-svg .messageText{fill:#333;stroke:none;}#mermaid-svg .labelBox{stroke:hsl(259.6261682243, 59.7765363128%, 87.9019607843%);fill:#ECECFF;}#mermaid-svg .labelText,#mermaid-svg .labelText&gt;tspan{fill:black;stroke:none;}#mermaid-svg .loopText,#mermaid-svg .loopText&gt;tspan{fill:black;stroke:none;}#mermaid-svg .loopLine{stroke-width:2px;stroke-dasharray:2,2;stroke:hsl(259.6261682243, 59.7765363128%, 87.9019607843%);fill:hsl(259.6261682243, 59.7765363128%, 87.9019607843%);}#mermaid-svg .note{stroke:#aaaa33;fill:#fff5ad;}#mermaid-svg .noteText,#mermaid-svg .noteText&gt;tspan{fill:black;stroke:none;}#mermaid-svg .activation0{fill:#f4f4f4;stroke:#666;}#mermaid-svg .activation1{fill:#f4f4f4;stroke:#666;}#mermaid-svg .activation2{fill:#f4f4f4;stroke:#666;}#mermaid-svg .actorPopupMenu{position:absolute;}#mermaid-svg .actorPopupMenuPanel{position:absolute;fill:#ECECFF;box-shadow:0px 8px 16px 0px rgba(0,0,0,0.2);filter:drop-shadow(3px 5px 2px rgb(0 0 0 / 0.4));}#mermaid-svg .actor-man line{stroke:hsl(259.6261682243, 59.7765363128%, 87.9019607843%);fill:#ECECFF;}#mermaid-svg .actor-man circle,#mermaid-svg line{stroke:hsl(259.6261682243, 59.7765363128%, 87.9019607843%);fill:#ECECFF;stroke-width:2px;}#mermaid-svg :root{--mermaid-font-family:\"trebuchet ms\",verdana,arial,sans-serif;}</style><g/><defs><symbol id=\"computer\" width=\"24\" height=\"24\"><path transform=\"scale(.5)\" d=\"M2 2v13h20v-13h-20zm18 11h-16v-9h16v9zm-10.228 6l.466-1h3.524l.467 1h-4.457zm14.228 3h-24l2-6h2.104l-1.33 4h18.45l-1.297-4h2.073l2 6zm-5-10h-14v-7h14v7z\"/></symbol></defs><defs><symbol id=\"database\" fill-rule=\"evenodd\" clip-rule=\"evenodd\"><path transform=\"scale(.5)\" d=\"M12.258.001l.256.004.255.005.253.008.251.01.249.012.247.015.246.016.242.019.241.02.239.023.236.024.233.027.231.028.229.031.225.032.223.034.22.036.217.038.214.04.211.041.208.043.205.045.201.046.198.048.194.05.191.051.187.053.183.054.18.056.175.057.172.059.168.06.163.061.16.063.155.064.15.066.074.033.073.033.071.034.07.034.069.035.068.035.067.035.066.035.064.036.064.036.062.036.06.036.06.037.058.037.058.037.055.038.055.038.053.038.052.038.051.039.05.039.048.039.047.039.045.04.044.04.043.04.041.04.04.041.039.041.037.041.036.041.034.041.033.042.032.042.03.042.029.042.027.042.026.043.024.043.023.043.021.043.02.043.018.044.017.043.015.044.013.044.012.044.011.045.009.044.007.045.006.045.004.045.002.045.001.045v17l-.001.045-.002.045-.004.045-.006.045-.007.045-.009.044-.011.045-.012.044-.013.044-.015.044-.017.043-.018.044-.02.043-.021.043-.023.043-.024.043-.026.043-.027.042-.029.042-.03.042-.032.042-.033.042-.034.041-.036.041-.037.041-.039.041-.04.041-.041.04-.043.04-.044.04-.045.04-.047.039-.048.039-.05.039-.051.039-.052.038-.053.038-.055.038-.055.038-.058.037-.058.037-.06.037-.06.036-.062.036-.064.036-.064.036-.066.035-.067.035-.068.035-.069.035-.07.034-.071.034-.073.033-.074.033-.15.066-.155.064-.16.063-.163.061-.168.06-.172.059-.175.057-.18.056-.183.054-.187.053-.191.051-.194.05-.198.048-.201.046-.205.045-.208.043-.211.041-.214.04-.217.038-.22.036-.223.034-.225.032-.229.031-.231.028-.233.027-.236.024-.239.023-.241.02-.242.019-.246.016-.247.015-.249.012-.251.01-.253.008-.255.005-.256.004-.258.001-.258-.001-.256-.004-.255-.005-.253-.008-.251-.01-.249-.012-.247-.015-.245-.016-.243-.019-.241-.02-.238-.023-.236-.024-.234-.027-.231-.028-.228-.031-.226-.032-.223-.034-.22-.036-.217-.038-.214-.04-.211-.041-.208-.043-.204-.045-.201-.046-.198-.048-.195-.05-.19-.051-.187-.053-.184-.054-.179-.056-.176-.057-.172-.059-.167-.06-.164-.061-.159-.063-.155-.064-.151-.066-.074-.033-.072-.033-.072-.034-.07-.034-.069-.035-.068-.035-.067-.035-.066-.035-.064-.036-.063-.036-.062-.036-.061-.036-.06-.037-.058-.037-.057-.037-.056-.038-.055-.038-.053-.038-.052-.038-.051-.039-.049-.039-.049-.039-.046-.039-.046-.04-.044-.04-.043-.04-.041-.04-.04-.041-.039-.041-.037-.041-.036-.041-.034-.041-.033-.042-.032-.042-.03-.042-.029-.042-.027-.042-.026-.043-.024-.043-.023-.043-.021-.043-.02-.043-.018-.044-.017-.043-.015-.044-.013-.044-.012-.044-.011-.045-.009-.044-.007-.045-.006-.045-.004-.045-.002-.045-.001-.045v-17l.001-.045.002-.045.004-.045.006-.045.007-.045.009-.044.011-.045.012-.044.013-.044.015-.044.017-.043.018-.044.02-.043.021-.043.023-.043.024-.043.026-.043.027-.042.029-.042.03-.042.032-.042.033-.042.034-.041.036-.041.037-.041.039-.041.04-.041.041-.04.043-.04.044-.04.046-.04.046-.039.049-.039.049-.039.051-.039.052-.038.053-.038.055-.038.056-.038.057-.037.058-.037.06-.037.061-.036.062-.036.063-.036.064-.036.066-.035.067-.035.068-.035.069-.035.07-.034.072-.034.072-.033.074-.033.151-.066.155-.064.159-.063.164-.061.167-.06.172-.059.176-.057.179-.056.184-.054.187-.053.19-.051.195-.05.198-.048.201-.046.204-.045.208-.043.211-.041.214-.04.217-.038.22-.036.223-.034.226-.032.228-.031.231-.028.234-.027.236-.024.238-.023.241-.02.243-.019.245-.016.247-.015.249-.012.251-.01.253-.008.255-.005.256-.004.258-.001.258.001zm-9.258 20.499v.01l.001.021.003.021.004.022.005.021.006.022.007.022.009.023.01.022.011.023.012.023.013.023.015.023.016.024.017.023.018.024.019.024.021.024.022.025.023.024.024.025.052.049.056.05.061.051.066.051.07.051.075.051.079.052.084.052.088.052.092.052.097.052.102.051.105.052.11.052.114.051.119.051.123.051.127.05.131.05.135.05.139.048.144.049.147.047.152.047.155.047.16.045.163.045.167.043.171.043.176.041.178.041.183.039.187.039.19.037.194.035.197.035.202.033.204.031.209.03.212.029.216.027.219.025.222.024.226.021.23.02.233.018.236.016.24.015.243.012.246.01.249.008.253.005.256.004.259.001.26-.001.257-.004.254-.005.25-.008.247-.011.244-.012.241-.014.237-.016.233-.018.231-.021.226-.021.224-.024.22-.026.216-.027.212-.028.21-.031.205-.031.202-.034.198-.034.194-.036.191-.037.187-.039.183-.04.179-.04.175-.042.172-.043.168-.044.163-.045.16-.046.155-.046.152-.047.148-.048.143-.049.139-.049.136-.05.131-.05.126-.05.123-.051.118-.052.114-.051.11-.052.106-.052.101-.052.096-.052.092-.052.088-.053.083-.051.079-.052.074-.052.07-.051.065-.051.06-.051.056-.05.051-.05.023-.024.023-.025.021-.024.02-.024.019-.024.018-.024.017-.024.015-.023.014-.024.013-.023.012-.023.01-.023.01-.022.008-.022.006-.022.006-.022.004-.022.004-.021.001-.021.001-.021v-4.127l-.077.055-.08.053-.083.054-.085.053-.087.052-.09.052-.093.051-.095.05-.097.05-.1.049-.102.049-.105.048-.106.047-.109.047-.111.046-.114.045-.115.045-.118.044-.12.043-.122.042-.124.042-.126.041-.128.04-.13.04-.132.038-.134.038-.135.037-.138.037-.139.035-.142.035-.143.034-.144.033-.147.032-.148.031-.15.03-.151.03-.153.029-.154.027-.156.027-.158.026-.159.025-.161.024-.162.023-.163.022-.165.021-.166.02-.167.019-.169.018-.169.017-.171.016-.173.015-.173.014-.175.013-.175.012-.177.011-.178.01-.179.008-.179.008-.181.006-.182.005-.182.004-.184.003-.184.002h-.37l-.184-.002-.184-.003-.182-.004-.182-.005-.181-.006-.179-.008-.179-.008-.178-.01-.176-.011-.176-.012-.175-.013-.173-.014-.172-.015-.171-.016-.17-.017-.169-.018-.167-.019-.166-.02-.165-.021-.163-.022-.162-.023-.161-.024-.159-.025-.157-.026-.156-.027-.155-.027-.153-.029-.151-.03-.15-.03-.148-.031-.146-.032-.145-.033-.143-.034-.141-.035-.14-.035-.137-.037-.136-.037-.134-.038-.132-.038-.13-.04-.128-.04-.126-.041-.124-.042-.122-.042-.12-.044-.117-.043-.116-.045-.113-.045-.112-.046-.109-.047-.106-.047-.105-.048-.102-.049-.1-.049-.097-.05-.095-.05-.093-.052-.09-.051-.087-.052-.085-.053-.083-.054-.08-.054-.077-.054v4.127zm0-5.654v.011l.001.021.003.021.004.021.005.022.006.022.007.022.009.022.01.022.011.023.012.023.013.023.015.024.016.023.017.024.018.024.019.024.021.024.022.024.023.025.024.024.052.05.056.05.061.05.066.051.07.051.075.052.079.051.084.052.088.052.092.052.097.052.102.052.105.052.11.051.114.051.119.052.123.05.127.051.131.05.135.049.139.049.144.048.147.048.152.047.155.046.16.045.163.045.167.044.171.042.176.042.178.04.183.04.187.038.19.037.194.036.197.034.202.033.204.032.209.03.212.028.216.027.219.025.222.024.226.022.23.02.233.018.236.016.24.014.243.012.246.01.249.008.253.006.256.003.259.001.26-.001.257-.003.254-.006.25-.008.247-.01.244-.012.241-.015.237-.016.233-.018.231-.02.226-.022.224-.024.22-.025.216-.027.212-.029.21-.03.205-.032.202-.033.198-.035.194-.036.191-.037.187-.039.183-.039.179-.041.175-.042.172-.043.168-.044.163-.045.16-.045.155-.047.152-.047.148-.048.143-.048.139-.05.136-.049.131-.05.126-.051.123-.051.118-.051.114-.052.11-.052.106-.052.101-.052.096-.052.092-.052.088-.052.083-.052.079-.052.074-.051.07-.052.065-.051.06-.05.056-.051.051-.049.023-.025.023-.024.021-.025.02-.024.019-.024.018-.024.017-.024.015-.023.014-.023.013-.024.012-.022.01-.023.01-.023.008-.022.006-.022.006-.022.004-.021.004-.022.001-.021.001-.021v-4.139l-.077.054-.08.054-.083.054-.085.052-.087.053-.09.051-.093.051-.095.051-.097.05-.1.049-.102.049-.105.048-.106.047-.109.047-.111.046-.114.045-.115.044-.118.044-.12.044-.122.042-.124.042-.126.041-.128.04-.13.039-.132.039-.134.038-.135.037-.138.036-.139.036-.142.035-.143.033-.144.033-.147.033-.148.031-.15.03-.151.03-.153.028-.154.028-.156.027-.158.026-.159.025-.161.024-.162.023-.163.022-.165.021-.166.02-.167.019-.169.018-.169.017-.171.016-.173.015-.173.014-.175.013-.175.012-.177.011-.178.009-.179.009-.179.007-.181.007-.182.005-.182.004-.184.003-.184.002h-.37l-.184-.002-.184-.003-.182-.004-.182-.005-.181-.007-.179-.007-.179-.009-.178-.009-.176-.011-.176-.012-.175-.013-.173-.014-.172-.015-.171-.016-.17-.017-.169-.018-.167-.019-.166-.02-.165-.021-.163-.022-.162-.023-.161-.024-.159-.025-.157-.026-.156-.027-.155-.028-.153-.028-.151-.03-.15-.03-.148-.031-.146-.033-.145-.033-.143-.033-.141-.035-.14-.036-.137-.036-.136-.037-.134-.038-.132-.039-.13-.039-.128-.04-.126-.041-.124-.042-.122-.043-.12-.043-.117-.044-.116-.044-.113-.046-.112-.046-.109-.046-.106-.047-.105-.048-.102-.049-.1-.049-.097-.05-.095-.051-.093-.051-.09-.051-.087-.053-.085-.052-.083-.054-.08-.054-.077-.054v4.139zm0-5.666v.011l.001.02.003.022.004.021.005.022.006.021.007.022.009.023.01.022.011.023.012.023.013.023.015.023.016.024.017.024.018.023.019.024.021.025.022.024.023.024.024.025.052.05.056.05.061.05.066.051.07.051.075.052.079.051.084.052.088.052.092.052.097.052.102.052.105.051.11.052.114.051.119.051.123.051.127.05.131.05.135.05.139.049.144.048.147.048.152.047.155.046.16.045.163.045.167.043.171.043.176.042.178.04.183.04.187.038.19.037.194.036.197.034.202.033.204.032.209.03.212.028.216.027.219.025.222.024.226.021.23.02.233.018.236.017.24.014.243.012.246.01.249.008.253.006.256.003.259.001.26-.001.257-.003.254-.006.25-.008.247-.01.244-.013.241-.014.237-.016.233-.018.231-.02.226-.022.224-.024.22-.025.216-.027.212-.029.21-.03.205-.032.202-.033.198-.035.194-.036.191-.037.187-.039.183-.039.179-.041.175-.042.172-.043.168-.044.163-.045.16-.045.155-.047.152-.047.148-.048.143-.049.139-.049.136-.049.131-.051.126-.05.123-.051.118-.052.114-.051.11-.052.106-.052.101-.052.096-.052.092-.052.088-.052.083-.052.079-.052.074-.052.07-.051.065-.051.06-.051.056-.05.051-.049.023-.025.023-.025.021-.024.02-.024.019-.024.018-.024.017-.024.015-.023.014-.024.013-.023.012-.023.01-.022.01-.023.008-.022.006-.022.006-.022.004-.022.004-.021.001-.021.001-.021v-4.153l-.077.054-.08.054-.083.053-.085.053-.087.053-.09.051-.093.051-.095.051-.097.05-.1.049-.102.048-.105.048-.106.048-.109.046-.111.046-.114.046-.115.044-.118.044-.12.043-.122.043-.124.042-.126.041-.128.04-.13.039-.132.039-.134.038-.135.037-.138.036-.139.036-.142.034-.143.034-.144.033-.147.032-.148.032-.15.03-.151.03-.153.028-.154.028-.156.027-.158.026-.159.024-.161.024-.162.023-.163.023-.165.021-.166.02-.167.019-.169.018-.169.017-.171.016-.173.015-.173.014-.175.013-.175.012-.177.01-.178.01-.179.009-.179.007-.181.006-.182.006-.182.004-.184.003-.184.001-.185.001-.185-.001-.184-.001-.184-.003-.182-.004-.182-.006-.181-.006-.179-.007-.179-.009-.178-.01-.176-.01-.176-.012-.175-.013-.173-.014-.172-.015-.171-.016-.17-.017-.169-.018-.167-.019-.166-.02-.165-.021-.163-.023-.162-.023-.161-.024-.159-.024-.157-.026-.156-.027-.155-.028-.153-.028-.151-.03-.15-.03-.148-.032-.146-.032-.145-.033-.143-.034-.141-.034-.14-.036-.137-.036-.136-.037-.134-.038-.132-.039-.13-.039-.128-.041-.126-.041-.124-.041-.122-.043-.12-.043-.117-.044-.116-.044-.113-.046-.112-.046-.109-.046-.106-.048-.105-.048-.102-.048-.1-.05-.097-.049-.095-.051-.093-.051-.09-.052-.087-.052-.085-.053-.083-.053-.08-.054-.077-.054v4.153zm8.74-8.179l-.257.004-.254.005-.25.008-.247.011-.244.012-.241.014-.237.016-.233.018-.231.021-.226.022-.224.023-.22.026-.216.027-.212.028-.21.031-.205.032-.202.033-.198.034-.194.036-.191.038-.187.038-.183.04-.179.041-.175.042-.172.043-.168.043-.163.045-.16.046-.155.046-.152.048-.148.048-.143.048-.139.049-.136.05-.131.05-.126.051-.123.051-.118.051-.114.052-.11.052-.106.052-.101.052-.096.052-.092.052-.088.052-.083.052-.079.052-.074.051-.07.052-.065.051-.06.05-.056.05-.051.05-.023.025-.023.024-.021.024-.02.025-.019.024-.018.024-.017.023-.015.024-.014.023-.013.023-.012.023-.01.023-.01.022-.008.022-.006.023-.006.021-.004.022-.004.021-.001.021-.001.021.001.021.001.021.004.021.004.022.006.021.006.023.008.022.01.022.01.023.012.023.013.023.014.023.015.024.017.023.018.024.019.024.02.025.021.024.023.024.023.025.051.05.056.05.06.05.065.051.07.052.074.051.079.052.083.052.088.052.092.052.096.052.101.052.106.052.11.052.114.052.118.051.123.051.126.051.131.05.136.05.139.049.143.048.148.048.152.048.155.046.16.046.163.045.168.043.172.043.175.042.179.041.183.04.187.038.191.038.194.036.198.034.202.033.205.032.21.031.212.028.216.027.22.026.224.023.226.022.231.021.233.018.237.016.241.014.244.012.247.011.25.008.254.005.257.004.26.001.26-.001.257-.004.254-.005.25-.008.247-.011.244-.012.241-.014.237-.016.233-.018.231-.021.226-.022.224-.023.22-.026.216-.027.212-.028.21-.031.205-.032.202-.033.198-.034.194-.036.191-.038.187-.038.183-.04.179-.041.175-.042.172-.043.168-.043.163-.045.16-.046.155-.046.152-.048.148-.048.143-.048.139-.049.136-.05.131-.05.126-.051.123-.051.118-.051.114-.052.11-.052.106-.052.101-.052.096-.052.092-.052.088-.052.083-.052.079-.052.074-.051.07-.052.065-.051.06-.05.056-.05.051-.05.023-.025.023-.024.021-.024.02-.025.019-.024.018-.024.017-.023.015-.024.014-.023.013-.023.012-.023.01-.023.01-.022.008-.022.006-.023.006-.021.004-.022.004-.021.001-.021.001-.021-.001-.021-.001-.021-.004-.021-.004-.022-.006-.021-.006-.023-.008-.022-.01-.022-.01-.023-.012-.023-.013-.023-.014-.023-.015-.024-.017-.023-.018-.024-.019-.024-.02-.025-.021-.024-.023-.024-.023-.025-.051-.05-.056-.05-.06-.05-.065-.051-.07-.052-.074-.051-.079-.052-.083-.052-.088-.052-.092-.052-.096-.052-.101-.052-.106-.052-.11-.052-.114-.052-.118-.051-.123-.051-.126-.051-.131-.05-.136-.05-.139-.049-.143-.048-.148-.048-.152-.048-.155-.046-.16-.046-.163-.045-.168-.043-.172-.043-.175-.042-.179-.041-.183-.04-.187-.038-.191-.038-.194-.036-.198-.034-.202-.033-.205-.032-.21-.031-.212-.028-.216-.027-.22-.026-.224-.023-.226-.022-.231-.021-.233-.018-.237-.016-.241-.014-.244-.012-.247-.011-.25-.008-.254-.005-.257-.004-.26-.001-.26.001z\"/></symbol></defs><defs><symbol id=\"clock\" width=\"24\" height=\"24\"><path transform=\"scale(.5)\" d=\"M12 2c5.514 0 10 4.486 10 10s-4.486 10-10 10-10-4.486-10-10 4.486-10 10-10zm0-2c-6.627 0-12 5.373-12 12s5.373 12 12 12 12-5.373 12-12-5.373-12-12-12zm5.848 12.459c.202.038.202.333.001.372-1.907.361-6.045 1.111-6.547 1.111-.719 0-1.301-.582-1.301-1.301 0-.512.77-5.447 1.125-7.445.034-.192.312-.181.343.014l.985 6.238 5.394 1.011z\"/></symbol></defs><defs><marker id=\"arrowhead\" refX=\"7.9\" refY=\"5\" markerUnits=\"userSpaceOnUse\" markerWidth=\"12\" markerHeight=\"12\" orient=\"auto\"><path d=\"M 0 0 L 10 5 L 0 10 z\"/></marker></defs><defs><marker id=\"crosshead\" markerWidth=\"15\" markerHeight=\"8\" orient=\"auto\" refX=\"4\" refY=\"4.5\"><path fill=\"none\" stroke=\"#000000\" stroke-width=\"1pt\" d=\"M 1,2 L 6,7 M 6,2 L 1,7\" style=\"stroke-dasharray: 0, 0;\"/></marker></defs><defs><marker id=\"filled-head\" refX=\"15.5\" refY=\"7\" markerWidth=\"20\" markerHeight=\"28\" orient=\"auto\"><path d=\"M 18,7 L9,13 L14,7 L9,1 Z\"/></marker></defs><defs><marker id=\"sequencenumber\" refX=\"15\" refY=\"15\" markerWidth=\"60\" markerHeight=\"40\" orient=\"auto\"><circle cx=\"15\" cy=\"15\" r=\"6\"/></marker></defs><text x=\"474\" y=\"80\" text-anchor=\"middle\" dominant-baseline=\"middle\" alignment-baseline=\"middle\" class=\"messageText\" dy=\"1em\" style=\"font-size: 16px; font-weight: 400;\">engineered prompt</text><line x1=\"276\" y1=\"111\" x2=\"671\" y2=\"111\" class=\"messageLine0\" stroke-width=\"2\" stroke=\"none\" marker-end=\"url(#arrowhead)\" style=\"fill: none;\"/><text x=\"477\" y=\"126\" text-anchor=\"middle\" dominant-baseline=\"middle\" alignment-baseline=\"middle\" class=\"messageText\" dy=\"1em\" style=\"font-size: 16px; font-weight: 400;\">configuration object</text><line x1=\"674\" y1=\"157\" x2=\"279\" y2=\"157\" class=\"messageLine0\" stroke-width=\"2\" stroke=\"none\" marker-end=\"url(#arrowhead)\" style=\"fill: none;\"/><text x=\"374\" y=\"172\" text-anchor=\"middle\" dominant-baseline=\"middle\" alignment-baseline=\"middle\" class=\"messageText\" dy=\"1em\" style=\"font-size: 16px; font-weight: 400;\">prompt</text><text x=\"374\" y=\"191\" text-anchor=\"middle\" dominant-baseline=\"middle\" alignment-baseline=\"middle\" class=\"messageText\" dy=\"1em\" style=\"font-size: 16px; font-weight: 400;\"> configuration object</text><line x1=\"276\" y1=\"221\" x2=\"471\" y2=\"221\" class=\"messageLine0\" stroke-width=\"2\" stroke=\"none\" marker-end=\"url(#arrowhead)\" style=\"fill: none;\"/><text x=\"774\" y=\"236\" text-anchor=\"middle\" dominant-baseline=\"middle\" alignment-baseline=\"middle\" class=\"messageText\" dy=\"1em\" style=\"font-size: 16px; font-weight: 400;\">configuration object</text><line x1=\"476\" y1=\"267\" x2=\"1071\" y2=\"267\" class=\"messageLine0\" stroke-width=\"2\" stroke=\"none\" marker-end=\"url(#arrowhead)\" style=\"fill: none;\"/><text x=\"777\" y=\"282\" text-anchor=\"middle\" dominant-baseline=\"middle\" alignment-baseline=\"middle\" class=\"messageText\" dy=\"1em\" style=\"font-size: 16px; font-weight: 400;\">evaluator object</text><line x1=\"1074\" y1=\"313\" x2=\"479\" y2=\"313\" class=\"messageLine0\" stroke-width=\"2\" stroke=\"none\" marker-end=\"url(#arrowhead)\" style=\"fill: none;\"/><text x=\"875\" y=\"328\" text-anchor=\"middle\" dominant-baseline=\"middle\" alignment-baseline=\"middle\" class=\"messageText\" dy=\"1em\" style=\"font-size: 16px; font-weight: 400;\">create with:</text><text x=\"875\" y=\"347\" text-anchor=\"middle\" dominant-baseline=\"middle\" alignment-baseline=\"middle\" class=\"messageText\" dy=\"1em\" style=\"font-size: 16px; font-weight: 400;\"> evaluator object</text><text x=\"875\" y=\"366\" text-anchor=\"middle\" dominant-baseline=\"middle\" alignment-baseline=\"middle\" class=\"messageText\" dy=\"1em\" style=\"font-size: 16px; font-weight: 400;\">prompt</text><line x1=\"476\" y1=\"393.6666666666667\" x2=\"1274\" y2=\"393.6666666666667\" class=\"messageLine0\" stroke-width=\"2\" stroke=\"none\" marker-end=\"url(#arrowhead)\" style=\"fill: none;\"/><text x=\"878\" y=\"409\" text-anchor=\"middle\" dominant-baseline=\"middle\" alignment-baseline=\"middle\" class=\"messageText\" dy=\"1em\" style=\"font-size: 16px; font-weight: 400;\">handle</text><line x1=\"1277\" y1=\"437.6666666666667\" x2=\"479\" y2=\"437.6666666666667\" class=\"messageLine0\" stroke-width=\"2\" stroke=\"none\" marker-end=\"url(#arrowhead)\" style=\"fill: none;\"/><text x=\"377\" y=\"453\" text-anchor=\"middle\" dominant-baseline=\"middle\" alignment-baseline=\"middle\" class=\"messageText\" dy=\"1em\" style=\"font-size: 16px; font-weight: 400;\">handle</text><line x1=\"474\" y1=\"481.6666666666667\" x2=\"279\" y2=\"481.6666666666667\" class=\"messageLine0\" stroke-width=\"2\" stroke=\"none\" marker-end=\"url(#arrowhead)\" style=\"fill: none;\"/><text x=\"775\" y=\"497\" text-anchor=\"middle\" dominant-baseline=\"middle\" alignment-baseline=\"middle\" class=\"messageText\" dy=\"1em\" style=\"font-size: 16px; font-weight: 400;\">invoke with</text><text x=\"775\" y=\"516\" text-anchor=\"middle\" dominant-baseline=\"middle\" alignment-baseline=\"middle\" class=\"messageText\" dy=\"1em\" style=\"font-size: 16px; font-weight: 400;\">message argument</text><line x1=\"276\" y1=\"544.1666666666667\" x2=\"1274\" y2=\"544.1666666666667\" class=\"messageLine0\" stroke-width=\"2\" stroke=\"none\" marker-end=\"url(#arrowhead)\" style=\"fill: none;\"/><text x=\"678\" y=\"559\" text-anchor=\"middle\" dominant-baseline=\"middle\" alignment-baseline=\"middle\" class=\"messageText\" dy=\"1em\" style=\"font-size: 16px; font-weight: 400;\">engineered prompt</text><text x=\"678\" y=\"578\" text-anchor=\"middle\" dominant-baseline=\"middle\" alignment-baseline=\"middle\" class=\"messageText\" dy=\"1em\" style=\"font-size: 16px; font-weight: 400;\">message</text><line x1=\"1277\" y1=\"608.1666666666667\" x2=\"79\" y2=\"608.1666666666667\" class=\"messageLine0\" stroke-width=\"2\" stroke=\"none\" marker-end=\"url(#arrowhead)\" style=\"fill: none;\"/><text x=\"174\" y=\"623\" text-anchor=\"middle\" dominant-baseline=\"middle\" alignment-baseline=\"middle\" class=\"messageText\" dy=\"1em\" style=\"font-size: 16px; font-weight: 400;\">LLM response</text><line x1=\"76\" y1=\"654.1666666666667\" x2=\"271\" y2=\"654.1666666666667\" class=\"messageLine0\" stroke-width=\"2\" stroke=\"none\" marker-end=\"url(#arrowhead)\" style=\"fill: none;\"/></svg>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#% mermaid\n",
    "sequenceDiagram\n",
    "  participant WWWOpenAI as WWW::OpenAI\n",
    "  participant User\n",
    "  participant llmfunc as llm-function\n",
    "  participant llmconf as llm-configuration\n",
    "  participant LLMConf as LLM configuration\n",
    "  participant LLMChatEval as LLM chat evaluator\n",
    "  participant AnonFunc as Anonymous function\n",
    "  User ->> llmconf: engineered prompt\n",
    "  llmconf ->> User: configuration object\n",
    "  User ->> llmfunc: prompt<br> configuration object\n",
    "  llmfunc ->> LLMChatEval: configuration object\n",
    "  LLMChatEval ->> llmfunc: evaluator object\n",
    "  llmfunc ->> AnonFunc: create with:<br> evaluator object<br>prompt\n",
    "  AnonFunc ->> llmfunc: handle\n",
    "  llmfunc ->> User: handle\n",
    "  User ->> AnonFunc: invoke with<br>message argument\n",
    "  AnonFunc ->> WWWOpenAI: engineered prompt<br>message\n",
    "  WWWOpenAI ->> User: LLM response \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "## On prompt engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is important to have a good, large collection of LLM prompts, that is easy to search.\n",
    "\n",
    "Also, the prompts should be ready to plug-in into LLM-functions or pipelines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some prompts from the collection are a \"simple\" strings, some are (function) templates.\n",
    "Here is an example of the latter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-> $a = \"paragraph\" { #`(Block|3366026942096) ... }"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm-prompt('NothingElse')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the template above filled-in with \"SQL\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ONLY give output in the form of a SQL.\n",
       "Never explain, suggest, or converse. Only return output in the specified form.\n",
       "If code is requested, give only code, no explanations or accompanying text.\n",
       "If a table is requested, give only a table, no other explanations or accompanying text.\n",
       "Do not describe your output. \n",
       "Do not explain your output. \n",
       "Do not suggest anything. \n",
       "Do not respond with anything other than the singularly demanded output. \n",
       "Do not apologize if you are incorrect, simply try again, never apologize or add text.\n",
       "Do not add anything to the output, give only the output as requested.Your outputs can take any form as long as requested."
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm-prompt('NothingElse')('SQL')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------\n",
    "\n",
    "## Using examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Easier that verbalizing a suitable prompt\n",
    "- More concrete and precise results than with a prompt\n",
    "- Fits inductive nature of LLMs\n",
    "    - Hence, better results are expected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the following number format normalization function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-> **@args, *%args { #`(Block|3366027093120) ... }"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my &num-norm = \n",
    "    llm-example-function([\n",
    "        '1,034' => '1_034', '13,003,553' => '13_003_553', '9,323,003,553' => '9_323_003_553',\n",
    "        '43 thousand USD' => '23E3', '3.9 thousand' => '3.9E3',\n",
    "        '23 million USD' => '23E6', '2.3 million' => '2.3E6',\n",
    "        '3.2343 trillion USD' => '3.2343E12', '0.3 trillion' => '0.3E12'\n",
    "    ]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to have a function that replaces whatever human readable number forms with \"proper\", \"parsable\" numbers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.78E3"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "&num-norm('3,78 thousand')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remark:** This a powerful technique which we are going to use the ***Grammar-LLM*** chain-of-responsibility example below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "\n",
    "## Using a Question Answering System (QAS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- With QAS we get answers to \"parameter questions\"\n",
    "- It is *assumed* that getting smaller output is more robust that getting full blown code\n",
    "- It is definitely cheaper\n",
    "- LLMs would not know your \"secret\" programming code\n",
    "- Its API, at most"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example (mod graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "I want to make a directed graph of the equivalence of the integers between 0 and 100 over mod 55.\n"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my $query = q:to/END/;\n",
    "I want to make a directed graph of the equivalence of the integers between 0 and 100 over mod 55.\n",
    "END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the number range? => 0 to 100\n",
      "Which mod to use? => 55\n",
      "What is the left boundary of the number range? => 0\n",
      "What is the right boundary of the number range? => 100\n",
      "Is the graph directed or not? True/False => True\n"
     ]
    }
   ],
   "source": [
    "my %ans =\n",
    "    llm-textual-answer($query, [\n",
    "        'What is the number range?',\n",
    "        'What is the left boundary of the number range?',\n",
    "        'What is the right boundary of the number range?',\n",
    "        'Which mod to use?',\n",
    "        'Is the graph directed or not? True/False'\n",
    "    ],\n",
    "    e => $conf3\n",
    "):pairs;\n",
    "\n",
    ".say for |%ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Graph(vertexes => 101, edges => 101, directed => True)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my @redges = (\n",
    "    (%ans{'What is the left boundary of the number range?'}).Int\n",
    "    ..\n",
    "    (%ans{'What is the right boundary of the number range?'}).Int\n",
    ").map({ $_.Str => (($_ ** 2) mod (%ans{'Which mod to use?'}.Int)).Str });\n",
    "\n",
    "my $gMod = Graph.new(@redges, directed => %ans{'Is the graph directed or not? True/False'}.lc eq 'true' ?? True !! False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%js\n",
    "js-d3-graph-plot(\n",
    "    $gMod.edges(:dataset),\n",
    "    :$background, :$title-color, :$edge-thickness, \n",
    "    vertex-size => 5,\n",
    "    vertex-color => 'SlateBlue',\n",
    "    directed => $gMod.directed,\n",
    "    title => \"Mod {%ans{'Which mod to use?'}} graph\", \n",
    "    width => 800,\n",
    "    height => 800, \n",
    "    force => {charge => {strength => -100}, link => {minDistance => 4}}\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2 (LSA pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Extract 20 topics from the text corpus aAbstracts using the method NNMF. \n",
       "Show statistical thesaurus with the words neural, function, and notebook.\n"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my $lsaCommand = q:to/END/;\n",
    "Extract 20 topics from the text corpus aAbstracts using the method NNMF. \n",
    "Show statistical thesaurus with the words neural, function, and notebook.\n",
    "END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lsaObj = (LatentSemanticAnalyzer()\n",
       ".make_document_term_matrix(docs=aAbstracts,\n",
       "                           stop_words=Automatic,\n",
       "                           stemming_rules=False,\n",
       "                           min_length=3)\n",
       ".apply_term_weight_functions(global_weight_func=\"IDF\",\n",
       "\t\t\t\t\t\t   local_weight_func=\"None\",\n",
       "\t\t\t\t\t\t   normalizer_func=\"Cosine\")\n",
       ".extract_topics(number_of_topics=40, min_number_of_documents_per_term=20, method=\"NNMF\", max_steps = 16)\n",
       ".echo_topics_interpretation(number_of_terms=20, wide_form=True)\n",
       ".echo_statistical_thesaurus(terms=stemmerObj.stemWords([\"neural\", \"function\", \"notebook\"]),\n",
       "\t\t\t\t\t\t  wide_form=True,\n",
       "\t\t\t\t\t\t  number_of_nearest_neighbors=12,\n",
       "\t\t\t\t\t\t  method=\"cosine\",\n",
       "\t\t\t\t\t\t  echo_function=lambda x: print(x.to_string())))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concretize($lsaCommand, template => 'LatentSemanticAnalysis', lang => 'Python', llm => 'gemini', model => 'gemini-1.5-flash');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remark:** The LSA pipeline produced above might need manual editing -- the target users of `concretize` are data scientists (full- or part-time.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An extension of that idea is to have an LLM-based classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[LatentSemanticAnalysis]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm-classify($lsaCommand, <Classification LatentSemanticAnalysis QuantilerRegression Recommendations>, e => $conf3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**REMARK:** Using different models for `llm-classify` can produce different results. Because of that: \n",
    "\n",
    "1. Accuracy, precision, and recall have to be evaluated for the queries we focus on\n",
    "2. The making of a more dedicated LLM classification persona should be considered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------\n",
    "\n",
    "## Grammar-LLM chain-of-responsibility utilization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we can make a grammar that can handle, say, 6080% of the user-formulated requests (in a given problem area) why use LLMs all the time?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup:\n",
    "\n",
    "- Assume we have conducted an opinion pull about programming languages.\n",
    "- We want to collect the number of positive and negative opinions for each programming language.\n",
    "- Most responders used simple statements, but some used elaborated ones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a grammar for parsing responses of language preferences questionnaire: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(LoveHateProg)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my grammar LoveHateProg {\n",
    "\trule TOP { <who> <verb> <lang> <:punct>? }\n",
    "\tregex who { 'I' | 'We' }\n",
    "\tregex verb { 'love' | 'hate' | ''* | '' }\n",
    "\tregex lang { 'Julia' | 'Perl' | 'Python' | 'R' | 'Raku' | 'WL' }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are corresponding actions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(LangPref)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my class LangPref {\n",
    "    method TOP($/) { make $<lang>.made => $<verb>.made }\n",
    "    method verb($/) { make so $/.Str ~~ / love | '' / }\n",
    "    method lang($/) { make $/.Str }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is how such are response is parsed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "R => False"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LoveHateProg.parse('I  R', actions => LangPref).made"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make an LLM function that produces similar results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-> **@args, *%args { #`(Block|3365994786192) ... }"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my &flop = llm-example-function([\n",
    "    'I love R' => '{\"R\" : true}', \n",
    "    'I love Pytgon' => '{\"Python\" : true}', \n",
    "    'I love Mathematica' => '{\"WL\" : true}', \n",
    "    'We think we like Python' => '{\"Python\" : true}',\n",
    "    'We hate Perl' => '{\"Perl\" : false}',\n",
    "    'I  Perl' => '{\"Perl\" : true}',\n",
    "    'we  Python' => '{\"Python\" : false}'],\n",
    "    e => $conf4o,\n",
    "    form => sub-parser('JSON'):drop\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{R => True}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "&flop(\"We like R most of the time\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "&get-lang-opinion"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub get-lang-opinion($st) {\n",
    "    my $op = LoveHateProg.parse($st, actions => LangPref).made;\n",
    "    return 'Grammar' => $op with $op;\n",
    "    return 'LLM' => &flop($st).head;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are statements and their parsing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my @statements = [\n",
    "    \"I love Pytgon\",\n",
    "    \"I love Python\",\n",
    "    \"I  WL\",\n",
    "    \"We like Perl\",\n",
    "    \"We like R most of the time\",\n",
    "    \"I hate Python\",\n",
    "    \"I like WL\",\n",
    "    \"I hate Mathematica\",\n",
    "    \"I  Raku\"\n",
    "];\n",
    "\n",
    "my @res = @statements.map({ get-lang-opinion($_) });\n",
    "\n",
    "@res.elems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the *parsed* results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM => Python => True\n",
      "Grammar => Python => True\n",
      "Grammar => WL => False\n",
      "LLM => Perl => True\n",
      "LLM => R => True\n",
      "Grammar => Python => False\n",
      "LLM => WL => True\n",
      "LLM => WL => False\n",
      "Grammar => Raku => True\n"
     ]
    }
   ],
   "source": [
    ".say for @res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remark:** Note that misspelled languages, unknown verbs, and longer statements are LLM-handled. The rest are grammar-handled."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raku => {True => 1}\n",
      "Perl => {True => 1}\n",
      "R => {True => 1}\n",
      "WL => {False => 2, True => 1}\n",
      "Python => {False => 1, True => 2}\n"
     ]
    }
   ],
   "source": [
    "my @opinions = @res.value.classify(*.key).map({ $_.key => $_.value.categorize(*.value).nodemap(*.elems) });\n",
    "\n",
    ".say for @opinions;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------\n",
    "\n",
    "## Using Literate Programming scripts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we ingest some text (from Wikipedia):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(chars => 16961 words => 2211 lines => 313)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my $txtEN = data-import('https://en.wikipedia.org/wiki/Bla_Bollobs', 'plaintext');\n",
    "\n",
    "text-stats($txtEN);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we extract a table themes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\"><thead><tr><th>theme</th><th>content</th></tr></thead><tbody><tr><td>Early life and education</td><td>Participated in International Mathematical Olympiads; studied under Paul Erds.</td></tr><tr><td>Career</td><td>Fellow of Trinity College; research in combinatorics and graph theory.</td></tr><tr><td>Awards and honours</td><td>Fellow of Royal Society; multiple prestigious awards.</td></tr><tr><td>Personal life</td><td>Married to Gabriella; has one son; sports enthusiast.</td></tr><tr><td>Selected works</td><td>Authored books on graph theory, combinatorics, and percolation.</td></tr><tr><td>References</td><td>Citations and sources for information on Bla Bollobs.</td></tr><tr><td>External links</td><td>Links to interviews and additional resources.</td></tr></tbody></table>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#% html\n",
    "my $tblThemes = llm-synthesize(llm-prompt(\"ThemeTableJSON\")($txtEN, \"article\", 10), e => $conf4o, form => sub-parser('JSON'):drop);\n",
    "$tblThemes ==> data-translation(field-names=><theme content>)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can have Literate Programming (LP) scripts that have several text-processing steps above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*(Live demo with \"Can AI Solve Science.\")*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Articles, blog posts\n",
    "\n",
    "[AA1] Anton Antonov,\n",
    "[\"Workflows with LLM functions\"](https://rakuforprediction.wordpress.com/2023/08/01/workflows-with-llm-functions/),\n",
    "(2023),\n",
    "[RakuForPrediction at WordPress](https://rakuforprediction.wordpress.com).\n",
    "\n",
    "[SW1] Stephen Wolfram,\n",
    "[\"The New World of LLM Functions: Integrating LLM Technology into the Wolfram Language\"](https://writings.stephenwolfram.com/2023/05/the-new-world-of-llm-functions-integrating-llm-technology-into-the-wolfram-language/),\n",
    "(2023),\n",
    "[Stephen Wolfram's Writings](https://writings.stephenwolfram.com)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notebooks\n",
    "\n",
    "[AAn1] Anton Antonov,\n",
    "[\"Workflows with LLM functions (in Raku)\"](https://community.wolfram.com/groups/-/m/t/2982320),\n",
    "(2023),\n",
    "[Wolfram Community](https://community.wolfram.com).\n",
    "\n",
    "[AAn2] Anton Antonov,\n",
    "[\"Workflows with LLM functions (in Python)\"](https://community.wolfram.com/groups/-/m/t/3027081),\n",
    "(2023),\n",
    "[Wolfram Community](https://community.wolfram.com).\n",
    "\n",
    "[AAn3] Anton Antonov,\n",
    "[\"Workflows with LLM functions (in WL)\"](https://community.wolfram.com/groups/-/m/t/3027081),\n",
    "(2023),\n",
    "[Wolfram Community](https://community.wolfram.com).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Packages\n",
    "\n",
    "#### Raku\n",
    "\n",
    "[AAp1] Anton Antonov,\n",
    "[LLM::Functions Raku package](https://github.com/antononcube/Raku-LLM-Functions),\n",
    "(2023-2024),\n",
    "[GitHub/antononcube](https://github.com/antononcube).\n",
    "([raku.land](https://raku.land/zef:antononcube/LLM::Functions))\n",
    "\n",
    "[AAp2] Anton Antonov,\n",
    "[LLM::Prompts Raku package](https://github.com/antononcube/Raku-LLM-Prompts),\n",
    "(2023-2024),\n",
    "[GitHub/antononcube](https://github.com/antononcube).\n",
    "([raku.land](https://raku.land/zef:antononcube/LLM::Prompts))\n",
    "\n",
    "[AAp3] Anton Antonov,\n",
    "[Jupyter::Chatbook Raku package](https://github.com/antononcube/Raku-Jupyter-Chatbook),\n",
    "(2023-2024),\n",
    "[GitHub/antononcube](https://github.com/antononcube).\n",
    "([raku.land](https://raku.land/zef:antononcube/Jupyter::Chatbook))\n",
    "\n",
    "#### Python\n",
    "\n",
    "[AAp4] Anton Antonov,\n",
    "[LLMFunctionObjects Python package](https://pypi.org/project/LLMFunctionObjects/),\n",
    "(2023-2024),\n",
    "[PyPI.org/antononcube](https://pypi.org/user/antononcube).\n",
    "\n",
    "[AAp5] Anton Antonov,\n",
    "[LLMPrompts Python package](https://pypi.org/project/LLMPrompts/),\n",
    "(2023-2024),\n",
    "[GitHub/antononcube](https://pypi.org/user/antononcube/).\n",
    "\n",
    "[AAp6] Anton Antonov,\n",
    "[JupyterChatbook Python package](https://pypi.org/project/JupyterChatbook/),\n",
    "(2023-2024),\n",
    "[GitHub/antononcube](https://pypi.org/user/antononcube/).\n",
    "\n",
    "[MWp1] Marc Wouts,\n",
    "[jupytext Python package](https://github.com/mwouts/jupytext),\n",
    "(2021-2024),\n",
    "[GitHub/mwouts](https://github.com/mwouts).\n",
    "\n",
    "#### R\n",
    "\n",
    "[TKp1] Tomasz Kalinowski, Kevin Ushey, JJ Allaire, RStudio, Yuan Tang,\n",
    "[reticulate R package](https://rstudio.github.io/reticulate/),\n",
    "(2016-2024)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Videos\n",
    "\n",
    "[AAv1] Anton Antonov,\n",
    "[\"Integrating Large Language Models with Raku\"](https://www.youtube.com/watch?v=-OxKqRrQvh0),\n",
    "(2023),\n",
    "[The Raku Conference 2023 at YouTube](https://www.youtube.com/@therakuconference6823)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "\n",
    "## *Setup*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use LLM::Configurations;\n",
    "use ML::FindTextualAnswer;\n",
    "use ML::NLPTemplateEngine;\n",
    "use Hash::Merge;\n",
    "use Graph;\n",
    "\n",
    "use JavaScript::D3;\n",
    "use JavaScript::Google::Charts;\n",
    "\n",
    "use Data::Reshapers;\n",
    "use Data::Summarizers;\n",
    "use Data::Generators;\n",
    "use Data::Importers;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JavaScript"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we prepare the notebook to visualize with JavaScript:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "require.config({\n     paths: {\n     d3: 'https://d3js.org/d3.v7.min'\n}});\n\nrequire(['d3'], function(d3) {\n     console.log(d3);\n});"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#% javascript\n",
    "require.config({\n",
    "     paths: {\n",
    "     d3: 'https://d3js.org/d3.v7.min'\n",
    "}});\n",
    "\n",
    "require(['d3'], function(d3) {\n",
    "     console.log(d3);\n",
    "});"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verification:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "(function(element) { require(['d3'], function(d3) {\n\n// set the dimensions and margins of the graph\nvar margin = {\"right\":40,\"top\":40,\"bottom\":40,\"left\":40},\n    width = 600 - margin.left - margin.right,\n    height = 400 - margin.top - margin.bottom;\n\n// append the svg object to the body of the page\nvar svg = d3\n   .select(element.get(0))\n  .append(\"svg\")\n    .attr(\"width\", width + margin.left + margin.right)\n    .attr(\"height\", height + margin.top + margin.bottom)\n    .style(\"background\", \"none\")\n  .append(\"g\")\n    .attr(\"transform\",\n          \"translate(\" + margin.left + \",\" + margin.top + \")\")\n\n// Obtain title\nvar title = \"\"\nvar titleFontSize = 16\n\nif ( title.length > 0 ) {\n    svg.append(\"text\")\n        .attr(\"x\", (width / 2))\n        .attr(\"y\", 0 - (margin.top / 2))\n        .attr(\"text-anchor\", \"middle\")\n        .style(\"font-size\", titleFontSize.toString() + \"px\")\n        .style(\"fill\", \"Black\")\n        .text(title);\n}\n\n// Obtain x-axis label\nvar xAxisLabel = \"\"\nvar xAxisLabelFontSize = 12\n\nif ( xAxisLabel.length > 0 ) {\n    svg.append(\"text\")\n        .attr(\"x\", (width / 2))\n        .attr(\"y\", height + margin.bottom - xAxisLabelFontSize/2)\n        .attr(\"text-anchor\", \"middle\")\n        .style(\"font-size\", xAxisLabelFontSize.toString() + \"px\")\n        .style(\"fill\", \"Black\")\n        .text(xAxisLabel);\n}\n\n// Obtain y-axis label\nvar yAxisLabel = \"\"\nvar yAxisLabelFontSize = 12\n\nif ( yAxisLabel.length > 0 ) {\n    svg.append(\"text\")\n        .attr(\"transform\", \"rotate(-90)\")\n        .attr(\"x\", - (height / 2))\n        .attr(\"y\", 0 - margin.left + yAxisLabelFontSize)\n        .attr(\"text-anchor\", \"middle\")\n        .style(\"font-size\", yAxisLabelFontSize.toString() + \"px\")\n        .style(\"fill\", \"Black\")\n        .text(yAxisLabel);\n}\n\n\n// Obtain data\nvar data = [{\"x\":1,\"y\":8.484680158394493e0},{\"x\":2,\"y\":4.4368777670316595e0},{\"y\":3.9025885089852643e0,\"x\":3},{\"y\":6.691594422870205e0,\"x\":4},{\"y\":8.114160351952478e0,\"x\":5},{\"x\":6,\"y\":4.889191962100688e0},{\"y\":6.661755209623527e0,\"x\":7},{\"x\":8,\"y\":9.596884670171434e0},{\"x\":9,\"y\":6.696488363518499e0},{\"x\":10,\"y\":8.166348193579761e0},{\"y\":8.737737529602436e0,\"x\":11},{\"y\":6.620422683872791e0,\"x\":12},{\"x\":13,\"y\":7.187777382872796e0},{\"y\":6.122675487331156e0,\"x\":14},{\"x\":15,\"y\":2.637594673545489e0},{\"x\":16,\"y\":5.050484554901699e0},{\"y\":1.2110042231877538e0,\"x\":17},{\"y\":9.279911588178413e0,\"x\":18},{\"x\":19,\"y\":3.4723215540874874e0},{\"y\":8.470335344721306e0,\"x\":20},{\"x\":21,\"y\":4.230580418355261e0},{\"x\":22,\"y\":8.345969816213184e0},{\"x\":23,\"y\":1.797482798819281e0},{\"x\":24,\"y\":4.956541752975234e0},{\"y\":1.747919860042807e0,\"x\":25},{\"x\":26,\"y\":6.273239734370939e0},{\"y\":1.0711283103844516e0,\"x\":27},{\"x\":28,\"y\":0.32452898347633985e0},{\"y\":9.396776192128165e0,\"x\":29},{\"x\":30,\"y\":5.822316915144152e0},{\"x\":31,\"y\":0.7348827677462277e0},{\"y\":6.7499574458123055e0,\"x\":32},{\"x\":33,\"y\":8.108759695538158e0},{\"y\":2.90081311816599e0,\"x\":34},{\"y\":3.9185227105933675e0,\"x\":35},{\"y\":5.332216688911878e0,\"x\":36},{\"y\":6.851825517045702e0,\"x\":37},{\"y\":1.839611912521717e0,\"x\":38},{\"x\":39,\"y\":1.0980860222710098e0},{\"y\":4.083611310510306e0,\"x\":40}]\n\nvar xMin = Math.min.apply(Math, data.map(function(o) { return o.x; }))\nvar xMax = Math.max.apply(Math, data.map(function(o) { return o.x; }))\n\nvar yMin = Math.min.apply(Math, data.map(function(o) { return o.y; }))\nvar yMax = Math.max.apply(Math, data.map(function(o) { return o.y; }))\n\n// X scale and Axis\nvar x = d3.scaleLinear()\n    .domain([xMin, xMax])\n    .range([0, width]);\n\n// Y scale and Axis\nvar y = d3.scaleLinear()\n    .domain([yMin, yMax])\n    .range([height, 0]);\n\nsvg\n  .append('g')\n  .attr(\"transform\", \"translate(0,\" + height + \")\")\n  .call(d3.axisBottom(x))\n\nsvg\n  .append('g')\n  .call(d3.axisLeft(y));\n\n// prepare a helper function\nvar lineFunc = d3.line()\n  .x(function(d) { return x(d.x) })\n  .y(function(d) { return y(d.y) })\n\n// Add the path using this helper function\nsvg.append('path')\n  .attr('d', lineFunc(data))\n  .attr(\"stroke-width\", 2)\n  .attr('stroke', \"steelblue\")\n  .attr('fill', 'none');\n\n}) })(element);\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#% js\n",
    "js-d3-list-line-plot(10.rand xx 40, background => 'none', stroke-width => 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we set a collection of visualization variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{background => 1F1F1F, edge-thickness => 3, title-color => Ivory, vertex-size => 6}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "my $title-color = 'Ivory';\n",
    "my $stroke-color = 'SlateGray';\n",
    "my $tooltip-color = 'LightBlue';\n",
    "my $tooltip-background-color = 'none';\n",
    "my $background = '1F1F1F';\n",
    "my $color-scheme = 'schemeTableau10';\n",
    "my $edge-thickness = 3;\n",
    "my $vertex-size = 6;\n",
    "my $mmd-theme = q:to/END/;\n",
    "%%{\n",
    "  init: {\n",
    "    'theme': 'forest',\n",
    "    'themeVariables': {\n",
    "      'lineColor': 'Ivory'\n",
    "    }\n",
    "  }\n",
    "}%%\n",
    "END\n",
    "my %force = collision => {iterations => 0, radius => 10},link => {distance => 180};\n",
    "my %force2 = charge => {strength => -30, iterations => 4}, collision => {radius => 50, iterations => 4}, link => {distance => 30};\n",
    "\n",
    "my %opts = :$background, :$title-color, :$edge-thickness, :$vertex-size;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Google Charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{bottom => 50, height => 90%, left => 50, right => 50, top => 50, width => 90%}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "my $format = 'html';\n",
    "my $titleTextStyle = { color => 'Ivory' };\n",
    "my $backgroundColor = '#1F1F1F';\n",
    "my $legendTextStyle = { color => 'Silver' };\n",
    "my $legend = { position => \"none\", textStyle => {fontSize => 14, color => 'Silver'} };\n",
    "\n",
    "my $hAxis = { title => 'x', titleTextStyle => { color => 'Silver' }, textStyle => { color => 'Gray'}, logScale => False, format => 'scientific'};\n",
    "my $vAxis = { title => 'y', titleTextStyle => { color => 'Silver' }, textStyle => { color => 'Gray'}, logScale => False, format => 'scientific'};\n",
    "\n",
    "my $annotations = {textStyle => {color => 'Silver', fontSize => 10}};\n",
    "my $chartArea = {left => 50, right => 50, top => 50, bottom => 50, width => '90%', height => '90%'};"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RakuChatbook",
   "language": "raku",
   "name": "raku"
  },
  "language_info": {
   "file_extension": ".raku",
   "mimetype": "text/x-raku",
   "name": "raku",
   "version": "6.d"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
