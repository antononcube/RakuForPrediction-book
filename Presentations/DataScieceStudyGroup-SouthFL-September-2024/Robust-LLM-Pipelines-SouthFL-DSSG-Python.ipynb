{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the \"Regressionizer\" and other \"standard\" packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Regressionizer import *\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.subplots as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "template='plotly_dark'\n",
    "data_color='darkgray'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from LLMFunctionObjects import *\n",
    "from LLMPrompts import *\n",
    "from DataTypeSystem import *\n",
    "import json\n",
    "import pandas\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext JupyterChatbook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLM access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[51, 39]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples=[]\n",
    "home = os.path.expanduser(\"~\")\n",
    "with open(home + '/.zshrc') as myfile:\n",
    "\tfor line in myfile.readlines():\n",
    "\t\tmatch = re.search(r'^export OPENAI_API_KEY=(:?.*)', line)\t\t\n",
    "\t\tif match:\n",
    "\t\t\topenai_api_key = match.group(1)\n",
    "\t\tmatch = re.search(r'^export PALM_API_KEY=(:?.*)', line)\n",
    "\t\tif match:\n",
    "\t\t\tpalm_api_key = match.group(1)\n",
    "\t\t\t\n",
    "[len(openai_api_key), len(palm_api_key)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "confOpenAI=llm_configuration(\"openai\", api_key=openai_api_key)\n",
    "confChatGPT=llm_configuration(\"chatgpt\", api_key=openai_api_key)\n",
    "confPaLM=llm_configuration(\"palm\", api_key=palm_api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "\n",
    "## Weather temperature data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load weather data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://raw.githubusercontent.com/antononcube/MathematicaVsR/master/Data/MathematicaVsR-Data-Atlanta-GA-USA-Temperature.csv\"\n",
    "dfTemperature = pd.read_csv(url)\n",
    "dfTemperature['DateObject'] = pd.to_datetime(dfTemperature['Date'], format='%Y-%m-%d')\n",
    "dfTemperature = dfTemperature[(dfTemperature['DateObject'].dt.year >= 2020) & (dfTemperature['DateObject'].dt.year <= 2023)]\n",
    "dfTemperature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert to \"numpy\" array: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_data = dfTemperature[['AbsoluteTime', 'Temperature']].to_numpy()\n",
    "temp_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "## Regressionizer Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = (\n",
    "    Regressionizer(temp_data)\n",
    "    .echo_data_summary()\n",
    "    .quantile_regression(knots=20, probs=[0.2, 0.5, 0.8])\n",
    "    .date_list_plot(title=\"Atlanta, Georgia, USA, Temperature, ℃\", template=template, data_color=data_color, width = 1200)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj.take_value().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj.outliers_plot(date_plot=True, width=1200, template = template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj.take_value().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "## Direct LLM access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "As of 2021, the estimated population of Brazil is around 213 million people."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%chat -i t0\n",
    "How many people live in Brazil?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "En 2021, la población estimada de Brasil es de alrededor de 213 millones de personas."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%chat -i t0\n",
    "Translated|Spanish^"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Well, bless your heart, darlin', I am Miss Anne. It's a pleasure to make your acquaintance. How may I assist you on this fine day?"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%chat -i sb --prompt=@SouthernBelleSpeak\n",
    "Hi! Who are you?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Mmm, greetings. Yoda, I am. Help you, I can. Speak freely, you may. Hmm?"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%chat -i yd --prompt=@Yoda\n",
    "Hi! Who are you?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ah, the color of my lightsaber, you ask. Green, it is. A symbol of knowledge and harmony. Many students, I have had. Young Jedi hopefuls, seeking wisdom and guidance. Train them, I did, in the ways of the Force. Strong in the Force, they were. Hmm."
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%chat -i yd \n",
    "What is the color of your laser saber? How many students did you have?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "## LLM pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ONLY give output in the form of a Python.\n",
      "Never explain, suggest, or converse. Only return output in the specified form.\n",
      "If code is requested, give only code, no explanations or accompanying text.\n",
      "If a table is requested, give only a table, no other explanations or accompanying text.\n",
      "Do not describe your output. \n",
      "Do not explain your output. \n",
      "Do not suggest anything. \n",
      "Do not respond with anything other than the singularly demanded output. \n",
      "Do not apologize if you are incorrect, simply try again, never apologize or add text.\n",
      "Do not add anything to the output, give only the output as requested. Your outputs can take any form as long as requested.\n"
     ]
    }
   ],
   "source": [
    "print(llm_prompt(\"NothingElse\")(\"Python\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = llm_synthesize([\n",
    "  \"What are the populations in India's states?\",\n",
    "  llm_prompt(\"NothingElse\")(\"JSON\")],\n",
    " llm_evaluator = llm_configuration(spec = \"chatgpt\", model = \"gpt-3.5-turbo\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_parser(\"JSON\",drop=True).parse(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(llm_prompt(\"NothingElse\")())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "## Statistics of output data types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Workflow:** We want to see and evaluate the distribution of data types of LLM-function results:\n",
    "\n",
    "1. Make a pipeline of LLM-functions\n",
    "\n",
    "1. Create a list of random inputs \"expected\" by the pipeline\n",
    "\n",
    "    - Or use the same input multiple times.\n",
    "\n",
    "1. Deduce the data type of each output\n",
    "\n",
    "1. Compute descriptive statistics\n",
    "\n",
    "**Remark:** These kind of statistical workflows can be slow and expensive. (With the current line-up of LLM services.)\n",
    "\n",
    "Let us reuse the workflow from the previous section and enhance it with data type outputs finding. More precisely we:\n",
    "\n",
    "1. Generate random music artist names (using an LLM query)\n",
    "\n",
    "1. Retrieve short biography and discography for each music artist\n",
    "\n",
    "1. Extract album-and-release-date data for each artist (with NER-by-LLM)\n",
    "\n",
    "1. Deduce the type for each output, using several different type representations\n",
    "\n",
    "The data types are investigated with the functions deduce_type and record_types of [\"DataTypeSystem\"](https://pypi.org/project/DataTypeSystem/) , [AAp5]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we define a data retrieval function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdb = llm_function(lambda x: f\"What is the short biography and discography of the artist {x}?\", e = llm_configuration(confChatGPT, max_tokens= 500))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we define (again) the NER function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "fner = llm_function(lambda a, b: f\"Extract {a} from the text: {b} . Give the result in a JSON format\", e = confChatGPT, form = sub_parser('JSON'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we find 10 random music artists:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " {'artists': ['Beyonce',\n",
       "   'Kendrick Lamar',\n",
       "   'Taylor Swift',\n",
       "   'Drake',\n",
       "   'Ariana Grande',\n",
       "   'Ed Sheeran',\n",
       "   'Rihanna',\n",
       "   'Travis Scott',\n",
       "   'Billie Eilish',\n",
       "   'Post Malone']},\n",
       " '']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artistNames = llm_function('',e=confChatGPT)(\"Give 10 random music artist names in a list in JSON format.\", \n",
    "                                        form = sub_parser('JSON'))\n",
    "artistNames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'artists': ['Beyonce',\n",
       "  'Kendrick Lamar',\n",
       "  'Taylor Swift',\n",
       "  'Drake',\n",
       "  'Ariana Grande',\n",
       "  'Ed Sheeran',\n",
       "  'Rihanna',\n",
       "  'Travis Scott',\n",
       "  'Billie Eilish',\n",
       "  'Post Malone']}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artistNames[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Beyonce',\n",
       " 'Kendrick Lamar',\n",
       " 'Taylor Swift',\n",
       " 'Drake',\n",
       " 'Ariana Grande',\n",
       " 'Ed Sheeran',\n",
       " 'Rihanna',\n",
       " 'Travis Scott',\n",
       " 'Billie Eilish',\n",
       " 'Post Malone']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artistNames2 = [list(item.items())[0][1] for item in artistNames if isinstance(item, dict)]\n",
    "artistNames2 = artistNames2[0]\n",
    "artistNames2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a loop that generates the biographies and does NER over them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['',\n",
       "  {'albums': [{'name': 'Dangerously in Love', 'release_date': '2003'},\n",
       "    {'name': \"B'Day\", 'release_date': '2006'},\n",
       "    {'name': 'I Am... Sasha Fierce', 'release_date': '2008'},\n",
       "    {'name': '4', 'release_date': '2011'},\n",
       "    {'name': 'Beyoncé', 'release_date': '2013'},\n",
       "    {'name': 'Lemonade', 'release_date': '2016'},\n",
       "    {'name': 'Everything Is Love', 'release_date': '2018'}]},\n",
       "  ''],\n",
       " ['',\n",
       "  {'albums': [{'name': 'Section.80', 'release_date': '2011'},\n",
       "    {'name': 'good kid, m.A.A.d city', 'release_date': '2012'},\n",
       "    {'name': 'To Pimp a Butterfly', 'release_date': '2015'},\n",
       "    {'name': 'DAMN.', 'release_date': '2017'},\n",
       "    {'name': 'Black Panther: The Album', 'release_date': '2018'},\n",
       "    {'name': 'Untitled Unmastered', 'release_date': '2016'}]},\n",
       "  ''],\n",
       " ['',\n",
       "  {'albums': [{'name': 'Taylor Swift', 'release_date': '2006'},\n",
       "    {'name': 'Fearless', 'release_date': '2008'},\n",
       "    {'name': 'Speak Now', 'release_date': '2010'},\n",
       "    {'name': 'Red', 'release_date': '2012'},\n",
       "    {'name': '1989', 'release_date': '2014'},\n",
       "    {'name': 'Reputation', 'release_date': '2017'},\n",
       "    {'name': 'Lover', 'release_date': '2019'},\n",
       "    {'name': 'Folklore', 'release_date': '2020'},\n",
       "    {'name': 'Evermore', 'release_date': '2020'}]},\n",
       "  ''],\n",
       " ['',\n",
       "  {'albums': [{'name': 'Thank Me Later', 'release_date': '2010'},\n",
       "    {'name': 'Take Care', 'release_date': '2011'},\n",
       "    {'name': 'Nothing Was the Same', 'release_date': '2013'},\n",
       "    {'name': 'Views', 'release_date': '2016'},\n",
       "    {'name': 'Scorpion', 'release_date': '2018'},\n",
       "    {'name': 'Certified Lover Boy', 'release_date': '2021'}]},\n",
       "  ''],\n",
       " ['',\n",
       "  {'albums': [{'name': 'Yours Truly', 'release_date': '2013'},\n",
       "    {'name': 'My Everything', 'release_date': '2014'},\n",
       "    {'name': 'Dangerous Woman', 'release_date': '2016'},\n",
       "    {'name': 'Sweetener', 'release_date': '2018'},\n",
       "    {'name': 'Thank U, Next', 'release_date': '2019'},\n",
       "    {'name': 'Positions', 'release_date': '2020'}]},\n",
       "  ''],\n",
       " ['',\n",
       "  {'albums': [{'name': '+ (Plus)', 'release_date': '2011'},\n",
       "    {'name': 'x (Multiply)', 'release_date': '2014'},\n",
       "    {'name': '÷ (Divide)', 'release_date': '2017'},\n",
       "    {'name': 'No. 6 Collaborations Project', 'release_date': '2019'},\n",
       "    {'name': '= (Equals)', 'release_date': '2021'}]},\n",
       "  ''],\n",
       " ['',\n",
       "  {'albums': [{'name': 'Music of the Sun', 'release_date': '2005'},\n",
       "    {'name': 'A Girl Like Me', 'release_date': '2006'},\n",
       "    {'name': 'Good Girl Gone Bad', 'release_date': '2007'},\n",
       "    {'name': 'Rated R', 'release_date': '2009'},\n",
       "    {'name': 'Loud', 'release_date': '2010'},\n",
       "    {'name': 'Talk That Talk', 'release_date': '2011'},\n",
       "    {'name': 'Unapologetic', 'release_date': '2012'},\n",
       "    {'name': 'Anti', 'release_date': '2016'}]},\n",
       "  ''],\n",
       " ['',\n",
       "  {'albums': [{'name': 'Rodeo', 'release_date': '2015'},\n",
       "    {'name': 'Birds in the Trap Sing McKnight', 'release_date': '2016'},\n",
       "    {'name': 'Astroworld', 'release_date': '2018'},\n",
       "    {'name': 'Utopia', 'release_date': '2021'}]},\n",
       "  ''],\n",
       " ['',\n",
       "  {'albums': [{'name': 'When We All Fall Asleep, Where Do We Go?',\n",
       "     'release_date': '2019'}]},\n",
       "  ''],\n",
       " ['',\n",
       "  {'albums': [{'name': 'Stoney', 'release_date': '2016'},\n",
       "    {'name': 'Beerbongs & Bentleys', 'release_date': '2018'},\n",
       "    {'name': \"Hollywood's Bleeding\", 'release_date': '2019'}]},\n",
       "  '']]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dbRes = []\n",
    "for a in artistNames2:\n",
    "    text = fdb(a)\n",
    "    recs = fner('album names and release dates', text)    \n",
    "    dbRes = dbRes + [recs, ]\n",
    "\n",
    "dbRes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we call deduce_type on each LLM output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Tuple([Atom(<class 'str'>), Assoc(Atom(<class 'str'>), Vector(Assoc(Atom(<class 'str'>), Atom(<class 'str'>), 2), 7), 1), Atom(<class 'str'>)])\",\n",
       " \"Tuple([Atom(<class 'str'>), Assoc(Atom(<class 'str'>), Vector(Assoc(Atom(<class 'str'>), Atom(<class 'str'>), 2), 6), 1), Atom(<class 'str'>)])\",\n",
       " \"Tuple([Atom(<class 'str'>), Assoc(Atom(<class 'str'>), Vector(Assoc(Atom(<class 'str'>), Atom(<class 'str'>), 2), 9), 1), Atom(<class 'str'>)])\",\n",
       " \"Tuple([Atom(<class 'str'>), Assoc(Atom(<class 'str'>), Vector(Assoc(Atom(<class 'str'>), Atom(<class 'str'>), 2), 6), 1), Atom(<class 'str'>)])\",\n",
       " \"Tuple([Atom(<class 'str'>), Assoc(Atom(<class 'str'>), Vector(Assoc(Atom(<class 'str'>), Atom(<class 'str'>), 2), 6), 1), Atom(<class 'str'>)])\",\n",
       " \"Tuple([Atom(<class 'str'>), Assoc(Atom(<class 'str'>), Vector(Assoc(Atom(<class 'str'>), Atom(<class 'str'>), 2), 5), 1), Atom(<class 'str'>)])\",\n",
       " \"Tuple([Atom(<class 'str'>), Assoc(Atom(<class 'str'>), Vector(Assoc(Atom(<class 'str'>), Atom(<class 'str'>), 2), 8), 1), Atom(<class 'str'>)])\",\n",
       " \"Tuple([Atom(<class 'str'>), Assoc(Atom(<class 'str'>), Vector(Assoc(Atom(<class 'str'>), Atom(<class 'str'>), 2), 4), 1), Atom(<class 'str'>)])\",\n",
       " \"Tuple([Atom(<class 'str'>), Assoc(Atom(<class 'str'>), Vector(Assoc(Atom(<class 'str'>), Atom(<class 'str'>), 2), 1), 1), Atom(<class 'str'>)])\",\n",
       " \"Tuple([Atom(<class 'str'>), Assoc(Atom(<class 'str'>), Vector(Assoc(Atom(<class 'str'>), Atom(<class 'str'>), 2), 3), 1), Atom(<class 'str'>)])\"]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[str(deduce_type(x)) for x in dbRes]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we redo the type deduction using the argument setting tally=True :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Tuple([(\"Assoc(Atom(<class \\'str\\'>), Vector(Assoc(Atom(<class \\'str\\'>), Atom(<class \\'str\\'>), 2), 7), 1)\", 1), (\"Atom(<class \\'str\\'>)\", 2)], 3)',\n",
       " 'Tuple([(\"Assoc(Atom(<class \\'str\\'>), Vector(Assoc(Atom(<class \\'str\\'>), Atom(<class \\'str\\'>), 2), 6), 1)\", 1), (\"Atom(<class \\'str\\'>)\", 2)], 3)',\n",
       " 'Tuple([(\"Assoc(Atom(<class \\'str\\'>), Vector(Assoc(Atom(<class \\'str\\'>), Atom(<class \\'str\\'>), 2), 9), 1)\", 1), (\"Atom(<class \\'str\\'>)\", 2)], 3)',\n",
       " 'Tuple([(\"Assoc(Atom(<class \\'str\\'>), Vector(Assoc(Atom(<class \\'str\\'>), Atom(<class \\'str\\'>), 2), 6), 1)\", 1), (\"Atom(<class \\'str\\'>)\", 2)], 3)',\n",
       " 'Tuple([(\"Assoc(Atom(<class \\'str\\'>), Vector(Assoc(Atom(<class \\'str\\'>), Atom(<class \\'str\\'>), 2), 6), 1)\", 1), (\"Atom(<class \\'str\\'>)\", 2)], 3)',\n",
       " 'Tuple([(\"Assoc(Atom(<class \\'str\\'>), Vector(Assoc(Atom(<class \\'str\\'>), Atom(<class \\'str\\'>), 2), 5), 1)\", 1), (\"Atom(<class \\'str\\'>)\", 2)], 3)',\n",
       " 'Tuple([(\"Assoc(Atom(<class \\'str\\'>), Vector(Assoc(Atom(<class \\'str\\'>), Atom(<class \\'str\\'>), 2), 8), 1)\", 1), (\"Atom(<class \\'str\\'>)\", 2)], 3)',\n",
       " 'Tuple([(\"Assoc(Atom(<class \\'str\\'>), Vector(Assoc(Atom(<class \\'str\\'>), Atom(<class \\'str\\'>), 2), 4), 1)\", 1), (\"Atom(<class \\'str\\'>)\", 2)], 3)',\n",
       " 'Tuple([(\"Assoc(Atom(<class \\'str\\'>), Vector(Assoc(Atom(<class \\'str\\'>), Atom(<class \\'str\\'>), 2), 1), 1)\", 1), (\"Atom(<class \\'str\\'>)\", 2)], 3)',\n",
       " 'Tuple([(\"Assoc(Atom(<class \\'str\\'>), Vector(Assoc(Atom(<class \\'str\\'>), Atom(<class \\'str\\'>), 2), 3), 1)\", 1), (\"Atom(<class \\'str\\'>)\", 2)], 3)']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[str(deduce_type(x, tally=True)) for x in dbRes]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the LLM outputs produce lists of dictionaries \"surrounded\" by strings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"[<class 'str'>, <class 'dict'>, <class 'str'>]\",\n",
       " \"[<class 'str'>, <class 'dict'>, <class 'str'>]\",\n",
       " \"[<class 'str'>, <class 'dict'>, <class 'str'>]\",\n",
       " \"[<class 'str'>, <class 'dict'>, <class 'str'>]\",\n",
       " \"[<class 'str'>, <class 'dict'>, <class 'str'>]\",\n",
       " \"[<class 'str'>, <class 'dict'>, <class 'str'>]\",\n",
       " \"[<class 'str'>, <class 'dict'>, <class 'str'>]\",\n",
       " \"[<class 'str'>, <class 'dict'>, <class 'str'>]\",\n",
       " \"[<class 'str'>, <class 'dict'>, <class 'str'>]\",\n",
       " \"[<class 'str'>, <class 'dict'>, <class 'str'>]\"]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[str(record_types(x)) for x in dbRes]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another record types finding call over the dictionaries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"{'albums': <class 'list'>}\",\n",
       " \"{'albums': <class 'list'>}\",\n",
       " \"{'albums': <class 'list'>}\",\n",
       " \"{'albums': <class 'list'>}\",\n",
       " \"{'albums': <class 'list'>}\",\n",
       " \"{'albums': <class 'list'>}\",\n",
       " \"{'albums': <class 'list'>}\",\n",
       " \"{'albums': <class 'list'>}\",\n",
       " \"{'albums': <class 'list'>}\",\n",
       " \"{'albums': <class 'list'>}\"]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[str(record_types(x[1])) for x in dbRes]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The statistics show that most likely the output we get from the execution of the LLM-functions pipeline is a list of a string and a dictionary. The dictionaries are most likely to be of length one, with \"albums\" as the key."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SciPyCentric",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
